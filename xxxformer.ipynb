{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1lyx0uUtKvTB",
        "fXWOL3TaKzz2",
        "rn4mhqeGWGbT"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakwa/xxxformer/blob/main/xxxformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# requirements.txt"
      ],
      "metadata": {
        "id": "vubyce0ywMHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADN5_hBilzlQ",
        "outputId": "9600c1ac-1015-4377-9c65-99562e8ae674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install reformer_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvlo2FAMv3qL",
        "outputId": "57613a8f-f844-4ce2-902f-d25e8b5b09ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reformer_pytorch\n",
            "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
            "Collecting einops\n",
            "  Downloading einops-0.5.0-py3-none-any.whl (36 kB)\n",
            "Collecting axial-positional-embedding>=0.1.0\n",
            "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
            "Collecting product-key-memory\n",
            "  Downloading product_key_memory-0.1.10.tar.gz (3.5 kB)\n",
            "Collecting local-attention\n",
            "  Downloading local_attention-1.4.3-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (4.1.1)\n",
            "Building wheels for collected packages: axial-positional-embedding, product-key-memory\n",
            "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2901 sha256=90df31ff30acda0cc93d8a8ace708f7b5a8ba238dd4f4e4e4b5fd5e94c45db7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/2c/c3/9a1cb267c0d0d9b6eeba7952addb32b17857d1f799690c27a8\n",
            "  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-py3-none-any.whl size=3072 sha256=a5f6b98110f79b734ad923b6bd9a29b2dc4b10226a98bf1841b94b484ea1fcb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/78/51/06648579a50c8e83f24ebfbdfd66462d1b88315a3491deba86\n",
            "Successfully built axial-positional-embedding product-key-memory\n",
            "Installing collected packages: product-key-memory, local-attention, einops, axial-positional-embedding, reformer-pytorch\n",
            "Successfully installed axial-positional-embedding-0.2.1 einops-0.5.0 local-attention-1.4.3 product-key-memory-0.1.10 reformer-pytorch-1.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdEzMXelt5GN"
      },
      "outputs": [],
      "source": [
        "import reformer_pytorch\n",
        "import pandas\n",
        "import sklearn\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igxTD7r-wPoN",
        "outputId": "99c977e1-b947-4a99-ffc6-3e682218fcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.utils"
      ],
      "metadata": {
        "id": "PQ9i2_q8TI9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 download data"
      ],
      "metadata": {
        "id": "jXLUb5ZaKldQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    source_url = 'https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/files/?p=%2Fall_six_datasets.zip&dl=1'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    res = requests.get(source_url, headers=headers)\n",
        "\n",
        "    with open('/content/drive/MyDrive/DATA_reformer/datasets.zip', 'wb') as f:\n",
        "        f.write(res.content)\n"
      ],
      "metadata": {
        "id": "Uk-umGQnTuGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 mask"
      ],
      "metadata": {
        "id": "CK3cRa1YKpV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class TriangularCausalMask():\n",
        "    def __init__(self, B, L, device=\"cpu\"):\n",
        "        mask_shape = [B, 1, L, L]\n",
        "        with torch.no_grad():\n",
        "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n",
        "\n",
        "\n",
        "class ProbMask():\n",
        "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
        "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
        "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
        "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
        "                    torch.arange(H)[None, :, None],\n",
        "                    index, :].to(device)\n",
        "        self._mask = indicator.view(scores.shape).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n"
      ],
      "metadata": {
        "id": "obcQnGROTkA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 metrics"
      ],
      "metadata": {
        "id": "VPSXrQVJKrbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def RSE(pred, true):\n",
        "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
        "\n",
        "\n",
        "def CORR(pred, true):\n",
        "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)  #.sum(0) axis=0       .mean(0) axis=0 \n",
        "    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n",
        "    return (u / d).mean(-1)\n",
        "\n",
        "\n",
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def RMSE(pred, true):\n",
        "    return np.sqrt(MSE(pred, true))\n",
        "\n",
        "\n",
        "def MAPE(pred, true):\n",
        "    return np.mean(np.abs((pred - true) / true))\n",
        "\n",
        "\n",
        "def MSPE(pred, true):\n",
        "    return np.mean(np.square((pred - true) / true))\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mae = MAE(pred, true)\n",
        "    mse = MSE(pred, true)\n",
        "    rmse = RMSE(pred, true)\n",
        "    mape = MAPE(pred, true)\n",
        "    mspe = MSPE(pred, true)\n",
        "\n",
        "    return mae, mse, rmse, mape, mspe\n"
      ],
      "metadata": {
        "id": "2XbBa4abTZV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 time features"
      ],
      "metadata": {
        "id": "1lyx0uUtKvTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.tseries import offsets\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "\n",
        "\n",
        "class TimeFeature:   #将dataframe转换为ndarry\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"()\"\n",
        "\n",
        "\n",
        "class SecondOfMinute(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.second / 59.0 - 0.5         # 0-1    --->     (-0.5,0.5)\n",
        "\n",
        "\n",
        "class MinuteOfHour(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.minute / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class HourOfDay(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.hour / 23.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfWeek(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.dayofweek / 6.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfMonth(TimeFeature):\n",
        "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.day - 1) / 30.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfYear(TimeFeature):\n",
        "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
        "\n",
        "\n",
        "class MonthOfYear(TimeFeature):\n",
        "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.month - 1) / 11.0 - 0.5\n",
        "\n",
        "\n",
        "class WeekOfYear(TimeFeature):\n",
        "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
        "\n",
        "\n",
        "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
        "    \"\"\"\n",
        "    Returns a list of time features that will be appropriate for the given frequency string.\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq_str\n",
        "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
        "    \"\"\"\n",
        "\n",
        "    features_by_offsets = {\n",
        "        offsets.YearEnd: [],\n",
        "        offsets.QuarterEnd: [MonthOfYear],\n",
        "        offsets.MonthEnd: [MonthOfYear],\n",
        "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
        "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Minute: [\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "        offsets.Second: [\n",
        "            SecondOfMinute,\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    offset = to_offset(freq_str)\n",
        "\n",
        "    for offset_type, feature_classes in features_by_offsets.items():\n",
        "        if isinstance(offset, offset_type):\n",
        "            return [cls() for cls in feature_classes]\n",
        "\n",
        "    supported_freq_msg = f\"\"\"\n",
        "    Unsupported frequency {freq_str}\n",
        "    The following frequencies are supported:\n",
        "        Y   - yearly\n",
        "            alias: A\n",
        "        M   - monthly\n",
        "        W   - weekly\n",
        "        D   - daily\n",
        "        B   - business days\n",
        "        H   - hourly\n",
        "        T   - minutely\n",
        "            alias: min\n",
        "        S   - secondly\n",
        "    \"\"\"\n",
        "    raise RuntimeError(supported_freq_msg)\n",
        "\n",
        "\n",
        "def time_features(dates, freq='h'):\n",
        "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])\n"
      ],
      "metadata": {
        "id": "HiHQBWT-TMQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 tools"
      ],
      "metadata": {
        "id": "fXWOL3TaKzz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
        "    if args.lradj == 'type1':\n",
        "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
        "    elif args.lradj == 'type2':\n",
        "        lr_adjust = {\n",
        "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
        "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
        "        }\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print('Updating learning rate to {}'.format(lr))\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "class StandardScaler():\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def transform(self, data):\n",
        "        return (data - self.mean) / self.std\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return (data * self.std) + self.mean\n",
        "\n",
        "\n",
        "def visual(true, preds=None, name='./pic/test.pdf'):\n",
        "    \"\"\"\n",
        "    Results visualization\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(true, label='GroundTruth', linewidth=2)\n",
        "    if preds is not None:\n",
        "        plt.plot(preds, label='Prediction', linewidth=2)\n",
        "    plt.legend()\n",
        "    plt.savefig(name, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "Fm6C7KYLTXIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.layers"
      ],
      "metadata": {
        "id": "7_lNv2HPb4BM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1AutoCorrelation"
      ],
      "metadata": {
        "id": "yLSM7Z0pcCej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "import os\n",
        "\n",
        "\n",
        "class AutoCorrelation(nn.Module):\n",
        "    \"\"\"\n",
        "    AutoCorrelation Mechanism with the following two phases:\n",
        "    (1) period-based dependencies discovery\n",
        "    (2) time delay aggregation\n",
        "    This block can replace the self-attention family mechanism seamlessly.\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(AutoCorrelation, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def time_delay_agg_training(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the training phase.\n",
        "        \"\"\"\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
        "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_inference(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the inference phase.\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_full(self, values, corr):\n",
        "        \"\"\"\n",
        "        Standard version of Autocorrelation\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
        "        return delays_agg\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        if L > S:\n",
        "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
        "            values = torch.cat([values, zeros], dim=1)\n",
        "            keys = torch.cat([keys, zeros], dim=1)\n",
        "        else:\n",
        "            values = values[:, :L, :, :]\n",
        "            keys = keys[:, :L, :, :]\n",
        "\n",
        "        # period-based dependencies\n",
        "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        res = q_fft * torch.conj(k_fft)\n",
        "        corr = torch.fft.irfft(res, dim=-1)\n",
        "\n",
        "        # time delay agg\n",
        "        if self.training:\n",
        "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "        else:\n",
        "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class AutoCorrelationLayer(nn.Module):\n",
        "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AutoCorrelationLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_correlation = correlation\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_correlation(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n"
      ],
      "metadata": {
        "id": "WqK3xTtab55F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2Autoformer encoder decoder"
      ],
      "metadata": {
        "id": "84o3uGkScJjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class my_Layernorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Special designed layernorm for the seasonal part\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(my_Layernorm, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_hat = self.layernorm(x)\n",
        "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
        "        return x_hat - bias\n",
        "\n",
        "\n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        x, _ = self.decomp1(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        res, _ = self.decomp2(x + y)\n",
        "        return res, attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer decoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
        "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.decomp3 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
        "                                    padding_mode='circular', bias=False)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x, trend1 = self.decomp1(x)\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "        x, trend2 = self.decomp2(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        x, trend3 = self.decomp3(x + y)\n",
        "\n",
        "        residual_trend = trend1 + trend2 + trend3\n",
        "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x, residual_trend\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
        "        for layer in self.layers:\n",
        "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "            trend = trend + residual_trend\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x, trend\n"
      ],
      "metadata": {
        "id": "Agyvwx9hcMwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3Embedding"
      ],
      "metadata": {
        "id": "eJ4TcAmNcbvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        # u = torch.tensor(300.) # 100<u<500                                 # **************************\n",
        "        # self.u_law_function = lambda w: (torch.log(torch.tensor(1.)+torch.abs(w)*u ))/(torch.log(torch.tensor(1.)+u))    #***************************\n",
        "    def forward(self, x):\n",
        "        # x = self.u_law_function(x)                              #***************************\n",
        "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FixedEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(FixedEmbedding, self).__init__()\n",
        "\n",
        "        w = torch.zeros(c_in, d_model).float()\n",
        "        w.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        w[:, 0::2] = torch.sin(position * div_term)\n",
        "        w[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.emb = nn.Embedding(c_in, d_model)\n",
        "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x).detach()\n",
        "\n",
        "\n",
        "class TemporalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
        "        super(TemporalEmbedding, self).__init__()\n",
        "\n",
        "        minute_size = 4\n",
        "        hour_size = 24\n",
        "        weekday_size = 7\n",
        "        day_size = 32\n",
        "        month_size = 13\n",
        "\n",
        "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
        "        if freq == 't':\n",
        "            self.minute_embed = Embed(minute_size, d_model)\n",
        "        self.hour_embed = Embed(hour_size, d_model)\n",
        "        self.weekday_embed = Embed(weekday_size, d_model)\n",
        "        self.day_embed = Embed(day_size, d_model)\n",
        "        self.month_embed = Embed(month_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "\n",
        "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
        "        hour_x = self.hour_embed(x[:, :, 3])\n",
        "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
        "        day_x = self.day_embed(x[:, :, 1])\n",
        "        month_x = self.month_embed(x[:, :, 0])\n",
        "\n",
        "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
        "\n",
        "\n",
        "class TimeFeatureEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
        "        super(TimeFeatureEmbedding, self).__init__()\n",
        "\n",
        "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
        "        d_inp = freq_map[freq]\n",
        "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "\n",
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class DataEmbedding_wo_pos(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding_wo_pos, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "O2GtrfuncaXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4SelfAttention_Family"
      ],
      "metadata": {
        "id": "xMx3dGK_oAJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "from reformer_pytorch import LSHSelfAttention\n",
        "import os\n",
        "\n",
        "\n",
        "class FullAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(FullAttention, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        scale = self.scale or 1. / sqrt(E)\n",
        "\n",
        "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)   #按照爱因斯坦求和约定，当一个单独项目内有标号变量出现两次，一次是上标，一次是下标时，则必须总和所有这单独项目的可能值。\n",
        "\n",
        "        if self.mask_flag:\n",
        "            if attn_mask is None:\n",
        "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
        "\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
        "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), A)\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class ProbAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(ProbAttention, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def _prob_QK(self, Q, K, sample_k, n_top):  # n_top: c*ln(L_q)\n",
        "        # Q [B, H, L, D]\n",
        "        B, H, L_K, E = K.shape\n",
        "        _, _, L_Q, _ = Q.shape\n",
        "\n",
        "        # calculate the sampled Q_K\n",
        "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
        "        index_sample = torch.randint(L_K, (L_Q, sample_k))  # real U = U_part(factor*ln(L_k))*L_q\n",
        "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
        "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
        "\n",
        "        # find the Top_k query with sparisty measurement\n",
        "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
        "        M_top = M.topk(n_top, sorted=False)[1]\n",
        "\n",
        "        # use the reduced Q to calculate Q_K\n",
        "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
        "                   torch.arange(H)[None, :, None],\n",
        "                   M_top, :]  # factor*ln(L_q)\n",
        "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))  # factor*ln(L_q)*L_k\n",
        "\n",
        "        return Q_K, M_top\n",
        "\n",
        "    def _get_initial_context(self, V, L_Q):\n",
        "        B, H, L_V, D = V.shape\n",
        "        if not self.mask_flag:\n",
        "            # V_sum = V.sum(dim=-2)\n",
        "            V_sum = V.mean(dim=-2)\n",
        "            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n",
        "        else:  # use mask\n",
        "            assert (L_Q == L_V)  # requires that L_Q == L_V, i.e. for self-attention only\n",
        "            contex = V.cumsum(dim=-2)\n",
        "        return contex\n",
        "\n",
        "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
        "        B, H, L_V, D = V.shape\n",
        "\n",
        "        if self.mask_flag:\n",
        "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  # nn.Softmax(dim=-1)(scores)\n",
        "\n",
        "        context_in[torch.arange(B)[:, None, None],\n",
        "        torch.arange(H)[None, :, None],\n",
        "        index, :] = torch.matmul(attn, V).type_as(context_in)\n",
        "        if self.output_attention:\n",
        "            attns = (torch.ones([B, H, L_V, L_V]) / L_V).type_as(attn).to(attn.device)\n",
        "            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n",
        "            return (context_in, attns)\n",
        "        else:\n",
        "            return (context_in, None)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L_Q, H, D = queries.shape\n",
        "        _, L_K, _, _ = keys.shape\n",
        "\n",
        "        queries = queries.transpose(2, 1)\n",
        "        keys = keys.transpose(2, 1)\n",
        "        values = values.transpose(2, 1)\n",
        "\n",
        "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item()  # c*ln(L_k)\n",
        "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item()  # c*ln(L_q)\n",
        "\n",
        "        U_part = U_part if U_part < L_K else L_K\n",
        "        u = u if u < L_Q else L_Q\n",
        "\n",
        "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
        "\n",
        "        # add scale factor\n",
        "        scale = self.scale or 1. / sqrt(D)\n",
        "        if scale is not None:\n",
        "            scores_top = scores_top * scale\n",
        "        # get the context\n",
        "        context = self._get_initial_context(values, L_Q)\n",
        "        # update the context with selected top_k queries\n",
        "        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n",
        "\n",
        "        return context.contiguous(), attn\n",
        "\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_attention = attention\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_attention(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n",
        "\n",
        "\n",
        "class ReformerLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
        "        super().__init__()\n",
        "        self.bucket_size = bucket_size\n",
        "        self.attn = LSHSelfAttention(\n",
        "            dim=d_model,\n",
        "            heads=n_heads,\n",
        "            bucket_size=bucket_size,\n",
        "            n_hashes=n_hashes,\n",
        "            causal=causal\n",
        "        )\n",
        "\n",
        "    def fit_length(self, queries):\n",
        "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
        "        B, N, C = queries.shape\n",
        "        if N % (self.bucket_size * 2) == 0:\n",
        "            return queries\n",
        "        else:\n",
        "            # fill the time series\n",
        "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
        "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        # in Reformer: defalut queries=keys\n",
        "        B, N, C = queries.shape\n",
        "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
        "        return queries, None\n"
      ],
      "metadata": {
        "id": "lIt9j_ZHoVKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5Transformer_EncDec"
      ],
      "metadata": {
        "id": "WTKTm3kIolKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
        "                                  out_channels=c_in,\n",
        "                                  kernel_size=3,\n",
        "                                  padding=2,\n",
        "                                  padding_mode='circular')\n",
        "        self.norm = nn.BatchNorm1d(c_in)\n",
        "        self.activation = nn.ELU()\n",
        "        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downConv(x.permute(0, 2, 1))\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxPool(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm2(x + y), attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        # x [B, L, D]\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
        "                 dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "\n",
        "        y = x = self.norm2(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm3(x + y)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "qU3EDdg-ongG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.data provider"
      ],
      "metadata": {
        "id": "Lm0TRcMPSr9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 data_loader"
      ],
      "metadata": {
        "id": "BgImJJEOW5fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from utils.timefeatures import time_features\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        print(df_raw)\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * 0.7)\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "    \n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "            cols.remove(self.target)\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            cols.remove(self.target)\n",
        "            cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n"
      ],
      "metadata": {
        "id": "cdfMzEkNSwzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2data_factory"
      ],
      "metadata": {
        "id": "zITfhuNwWve4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_dict = {\n",
        "    'ETTh1': Dataset_ETT_hour,\n",
        "    'ETTh2': Dataset_ETT_hour,\n",
        "    'ETTm1': Dataset_ETT_minute,\n",
        "    'ETTm2': Dataset_ETT_minute,\n",
        "    'custom': Dataset_Custom,\n",
        "}\n",
        "\n",
        "\n",
        "def data_provider(args, flag):\n",
        "    Data = data_dict[args.data]\n",
        "    timeenc = 0 if args.embed != 'timeF' else 1\n",
        "    print(Data)\n",
        "    print(timeenc)\n",
        "    if flag == 'test':\n",
        "        shuffle_flag = False\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "    elif flag == 'pred':\n",
        "        shuffle_flag = False\n",
        "        drop_last = False\n",
        "        batch_size = 1\n",
        "        freq = args.freq\n",
        "        Data = Dataset_Pred\n",
        "    else:\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "\n",
        "    data_set = Data(\n",
        "        root_path=args.root_path,\n",
        "        data_path=args.data_path,\n",
        "        flag=flag,\n",
        "        size=[args.seq_len, args.label_len, args.pred_len],\n",
        "        features=args.features,\n",
        "        target=args.target,\n",
        "        timeenc=timeenc,\n",
        "        freq=freq\n",
        "    )\n",
        "    print(flag, len(data_set))\n",
        "    data_loader = DataLoader(\n",
        "        data_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_flag,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=drop_last)\n",
        "    return data_set, data_loader\n"
      ],
      "metadata": {
        "id": "IWZeKnfeUUn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Dataset_ETT_hour(\n",
        "        root_path='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/',\n",
        "        data_path='REFINED_NBC news G16B3-QP28.csv',\n",
        "        flag='test',\n",
        "        size=[98, 48, 24],\n",
        "        features='M',\n",
        "        target='OT',\n",
        "        timeenc=1,\n",
        "        # freq='d'\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "xpHbE97AJFMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 0\n",
        "# for item in data_set:\n",
        "#   if i < 1:\n",
        "#     i = i + 1\n",
        "#     print(item)"
      ],
      "metadata": {
        "id": "c5AAmQxXN9JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_provider.timeenc"
      ],
      "metadata": {
        "id": "FhuwQ28lJKTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args.data\n",
        "# args.freq\n",
        "# args.target,\n",
        "# args.features"
      ],
      "metadata": {
        "id": "xN2VPTltANAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args.root_path,"
      ],
      "metadata": {
        "id": "ggqTaWtqBZpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''data_set'''\n",
        "# i = 0\n",
        "# print(\"data_set:\", data_set)\n",
        "# for item in data_loader:\n",
        "#   i = i+1\n",
        "#   if i < 5:\n",
        "#     print(\"item:\", item)\n",
        "#     print(\"item size:\", len(item))"
      ],
      "metadata": {
        "id": "SMhEdQ1__8a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.model"
      ],
      "metadata": {
        "id": "rn4mhqeGWGbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.0.transformer"
      ],
      "metadata": {
        "id": "XEQKNrGVV1nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Embed import DataEmbedding, DataEmbedding_wo_pos\n",
        "# from layers.AutoCorrelation import AutoCorrelation, AutoCorrelationLayer\n",
        "# from layers.Autoformer_EncDec import Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer is the first method to achieve the series-wise connection,\n",
        "    with inherent O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_transformer, self).__init__()\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.label_len = configs.label_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Decomp\n",
        "        kernel_size = configs.moving_avg\n",
        "        self.decomp = series_decomp(kernel_size)\n",
        "\n",
        "        # Embedding\n",
        "        # The series-wise connection inherently contains the sequential information.\n",
        "        # Thus, we can discard the position embedding of transformers.\n",
        "        self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding_wo_pos(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(True, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.c_out,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # decomp init\n",
        "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
        "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device)\n",
        "        seasonal_init, trend_init = self.decomp(x_enc)\n",
        "        # decoder input\n",
        "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
        "        seasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n",
        "        # enc\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        # dec\n",
        "        dec_out = self.dec_embedding(seasonal_init, x_mark_dec)\n",
        "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
        "                                                 trend=trend_init)\n",
        "        # final\n",
        "        dec_out = trend_part + seasonal_part\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "3aIRCR44bstE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1.autoformer"
      ],
      "metadata": {
        "id": "lh-wb_oDcZq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_autoformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Vanilla Transformer with O(L^2) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_autoformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "UzH_MdaLV6fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 informer"
      ],
      "metadata": {
        "id": "pO1t1HZNfST2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, ProbAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_informer(nn.Module):\n",
        "    \"\"\"\n",
        "    Informer with Propspare attention in O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_informer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            [\n",
        "                ConvLayer(\n",
        "                    configs.d_model\n",
        "                ) for l in range(configs.e_layers - 1)\n",
        "            ] if configs.distil else None,\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "d8hMhyLGfUJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 reformer"
      ],
      "metadata": {
        "id": "phxv-52XfZxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import ReformerLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_reformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Reformer with O(LlogL) complexity\n",
        "    - It is notable that Reformer is not proposed for time series forecasting, in that it cannot accomplish the cross attention.\n",
        "    - Here is only one adaption in BERT-style, other possible implementations can also be acceptable.\n",
        "    - The hyper-parameters, such as bucket_size and n_hashes, need to be further tuned.\n",
        "    The official repo of Reformer (https://github.com/lucidrains/reformer-pytorch) can be very helpful, if you have any questiones.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super(Model_reformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    ReformerLayer(None, configs.d_model, configs.n_heads, bucket_size=configs.bucket_size,\n",
        "                                  n_hashes=configs.n_hashes),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        self.projection = nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # add placeholder\n",
        "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        x_mark_enc = torch.cat([x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        # Reformer: encoder only\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        enc_out = self.projection(enc_out)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return enc_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return enc_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "OWuGfTFWfhMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.exp"
      ],
      "metadata": {
        "id": "eyAd4Xzgdn7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 exp_basic"
      ],
      "metadata": {
        "id": "vZnDaWqEd1cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Exp_Basic(object):\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.device = self._acquire_device()\n",
        "        self.model = self._build_model().to(self.device)\n",
        "\n",
        "    def _build_model(self):\n",
        "        raise NotImplementedError\n",
        "        return None\n",
        "\n",
        "    def _acquire_device(self):\n",
        "        if self.args.use_gpu:\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
        "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
        "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
        "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "            print('Use CPU')\n",
        "        return device\n",
        "\n",
        "    def _get_data(self):\n",
        "        pass\n",
        "\n",
        "    def vali(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def test(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "_kDMmjLddsCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 exp_main"
      ],
      "metadata": {
        "id": "eaqW13S4fAXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from data_provider.data_factory import data_provider\n",
        "# from exp.exp_basic import Exp_Basic\n",
        "# from models import Informer, Autoformer, Transformer, Reformer\n",
        "# from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
        "# from utils.metrics import metric\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Exp_Main(Exp_Basic):\n",
        "    def __init__(self, args):\n",
        "        super(Exp_Main, self).__init__(args)\n",
        "\n",
        "    def _build_model(self):\n",
        "        model_dict = {\n",
        "            'Autoformer': Model_autoformer,\n",
        "            'Transformer': Model_transformer,\n",
        "            'Informer': Model_informer,\n",
        "            'Reformer': Model_reformer,\n",
        "        }\n",
        "        # model_dict = {\n",
        "        #     'Autoformer': Autoformer,\n",
        "        #     'Transformer': Transformer,\n",
        "        #     'Informer': Informer,\n",
        "        #     'Reformer': Reformer,\n",
        "        # }\n",
        "        # model = model_dict[self.args.model].Model(self.args).float()\n",
        "        model = model_dict[self.args.model](self.args).float()\n",
        "\n",
        "\n",
        "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
        "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
        "        return model\n",
        "\n",
        "    def _get_data(self, flag):\n",
        "        data_set, data_loader = data_provider(self.args, flag)\n",
        "        return data_set, data_loader\n",
        "\n",
        "    def _select_optimizer(self):\n",
        "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _select_criterion(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def vali(self, vali_data, vali_loader, criterion):\n",
        "        total_loss = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "\n",
        "                pred = outputs.detach().cpu()\n",
        "                true = batch_y.detach().cpu()\n",
        "\n",
        "                loss = criterion(pred, true)\n",
        "\n",
        "                total_loss.append(loss)\n",
        "        total_loss = np.average(total_loss)\n",
        "        self.model.train()\n",
        "        return total_loss\n",
        "\n",
        "    def train(self, setting):\n",
        "        train_data, train_loader = self._get_data(flag='train')\n",
        "        vali_data, vali_loader = self._get_data(flag='val')\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        path = os.path.join(self.args.checkpoints, setting)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        time_now = time.time()\n",
        "\n",
        "        train_steps = len(train_loader)\n",
        "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
        "\n",
        "        model_optim = self._select_optimizer()\n",
        "        criterion = self._select_criterion()\n",
        "\n",
        "        if self.args.use_amp:\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        for epoch in range(self.args.train_epochs):\n",
        "            iter_count = 0\n",
        "            train_loss = []\n",
        "\n",
        "            self.model.train()\n",
        "            epoch_time = time.time()\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "                iter_count += 1\n",
        "                model_optim.zero_grad()\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                        loss = criterion(outputs, batch_y)\n",
        "                        train_loss.append(loss.item())\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
        "\n",
        "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    train_loss.append(loss.item())\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                if self.args.use_amp:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(model_optim)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    model_optim.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            train_loss = np.average(train_loss)\n",
        "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
        "            test_loss = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
        "            early_stopping(vali_loss, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
        "\n",
        "        best_model_path = path + '/' + 'checkpoint.pth'\n",
        "        self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def test(self, setting, test=0):\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "        if test:\n",
        "            print('loading model')\n",
        "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        folder_path = './test_results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                outputs = outputs.detach().cpu().numpy()\n",
        "                batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "                if i % 20 == 0:\n",
        "                    input = batch_x.detach().cpu().numpy()\n",
        "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
        "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
        "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        trues = np.array(trues)\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
        "        print('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f = open(\"result.txt\", 'a')\n",
        "        f.write(setting + \"  \\n\")\n",
        "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f.write('\\n')\n",
        "        f.write('\\n')\n",
        "        f.close()\n",
        "\n",
        "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
        "        np.save(folder_path + 'pred.npy', preds)\n",
        "        np.save(folder_path + 'true.npy', trues)\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, setting, load=False):\n",
        "        pred_data, pred_loader = self._get_data(flag='pred')\n",
        "\n",
        "        if load:\n",
        "            path = os.path.join(self.args.checkpoints, setting)\n",
        "            best_model_path = path + '/' + 'checkpoint.pth'\n",
        "            self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                preds.append(pred)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        np.save(folder_path + 'real_prediction.npy', preds)\n",
        "\n",
        "        return preds"
      ],
      "metadata": {
        "id": "hoDRz8yifA2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict"
      ],
      "metadata": {
        "id": "MUdH5LufYdg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n"
      ],
      "metadata": {
        "id": "jb1pRBEDYiqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d1be2d-05da-4118-aee2-1e36b58e1496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() \n",
        "import torch\n",
        "torch.cuda.set_device(0)"
      ],
      "metadata": {
        "id": "yYISGR-rbc2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "# from exp.exp_main import Exp_Main#exp stands for experiments\n",
        "import random\n",
        "import numpy as np\n",
        "# from utils.tools import dotdict\n",
        "\n",
        "fix_seed = 2021 \n",
        "random.seed(fix_seed)\n",
        "torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')#模型id\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',#选择模型\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')#数据类型\n",
        "parser.add_argument('--root_path', type=str, default='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', help='root path of the data file')#数据文件夹路径\n",
        "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')#具体文件\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')#预测类别\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')#不太懂 OT好像代表Output Target,要预测的单变量\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='/content/drive/MyDrive/DATA_reformer/checkpoints/', help='location of model checkpoints')#保存模型\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')#输入序列长度\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')#这个label_len未完全搞懂\n",
        "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')#输出序列长度\n",
        "\n",
        "# model define\n",
        "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')#encoder input size\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')#decoder input size\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')#输出长度\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')#dimension of model\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')#num of heads \n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')#num of encoder layers\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')#num of decoder layers\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')#dimension of fcn\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')#窗口滑动平均数\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')#attn factor不太理解\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)#是否在encoder里面使用知识蒸馏\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')#dropout\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')#time features encoding不太能get到\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')#激活函数default=gelu\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')#encoder的output_attention是否输出\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')#是否预测未见的未来数据,也就是是否进行推理的意思\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')# num_workers是加载数据(batch)的线程数目\n",
        "parser.add_argument('--itr', type=int, default=2, help='experiments times')#实验次数\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')#就是epoch\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')#bathsize\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')#patience: 当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')#lr\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')#test\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')#loss is mse\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')#adjust learning-rate\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)#使用自动混合精度训练\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args = dotdict()\n",
        "args.target = 'OT'\n",
        "args.des = 'test'\n",
        "args.dropout = 0.05\n",
        "args.num_workers = 10\n",
        "args.gpu = 0\n",
        "args.lradj = 'type1'\n",
        "args.devices = '0'\n",
        "args.use_gpu = True\n",
        "args.use_multi_gpu = False\n",
        "# if args.use_gpu and args.use_multi_gpu: #是否使用多卡的判断\n",
        "#     args.dvices = args.devices.replace(' ', '')\n",
        "#     device_ids = args.devices.split(',')\n",
        "#     args.device_ids = [int(id_) for id_ in device_ids]\n",
        "#     args.gpu = args.device_ids[0]\n",
        "args.freq = 'h'\n",
        "args.checkpoints = '/content/drive/MyDrive/DATA_reformer/checkpoints/'\n",
        "args.bucket_size = 4\n",
        "args.n_hashes = 4\n",
        "args.is_trainging = True\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path ='REFINED_NBC news G16B3-QP28.csv' \n",
        "args.model_id='ETTh1_96_24'\n",
        "args.model = 'Autoformer'\n",
        "args.data = 'ETTh1'\n",
        "args.features = 'M'\n",
        "args.seq_len = 96\n",
        "args.label_len = 48\n",
        "args.pred_len = 24\n",
        "args.e_layers = 2\n",
        "args.d_layers = 1\n",
        "args.n_heads = 8\n",
        "args.factor = 1\n",
        "args.enc_in = 7\n",
        "args.dec_in =7\n",
        "args.c_out = 7\n",
        "args.d_model = 512\n",
        "\n",
        "args.des = 'Exp'\n",
        "args.itr = 1      #1\n",
        "args.d_ff = 2048\n",
        "args.moving_avg = 25\n",
        "args.factor = 1\n",
        "args.distil = True\n",
        "args.output_attention = False\n",
        "args.patience= 3\n",
        "args.learning_rate = 0.0001\n",
        "args.batch_size = 32 \n",
        "args.embed = 'timeF'\n",
        "args.activation = 'gelu'\n",
        "args.use_amp = False\n",
        "args.loss = 'mse'\n",
        "args.train_epochs = 10    #10\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "# Exp = Exp_Main\n",
        "\n"
      ],
      "metadata": {
        "id": "S3PkcjfqbkHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38077442-5a4a-4157-c493-0b49522c1713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': '/content/drive/MyDrive/DATA_reformer/checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', 'data_path': 'REFINED_NBC news G16B3-QP28.csv', 'model_id': 'ETTh1_96_24', 'model': 'Autoformer', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "for ii in range(args.itr):#itr就是实验次数可不是epoch，parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "        args.model_id,\n",
        "        args.model,\n",
        "        args.data,\n",
        "        args.features,\n",
        "        args.seq_len,\n",
        "        args.label_len,\n",
        "        args.pred_len,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        args.d_layers,\n",
        "        args.d_ff,\n",
        "        args.factor,\n",
        "        args.embed,\n",
        "        args.distil,\n",
        "        args.des, ii)\n",
        "\n",
        "    exp = Exp_Main(args)  # set experiments\n",
        "    print(1)\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)#setting是用来保存模型的名字用的，很细节\n",
        "    print(2)\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(3)\n",
        "\n"
      ],
      "metadata": {
        "id": "gkA3f_QHeIlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53e603e-0f82-4382-de49-ebd6015feee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            "1\n",
            ">>>>>>>start training : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "train 8521\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "val 2857\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "test 2857\n",
            "\titers: 100, epoch: 1 | loss: 1.1393069\n",
            "\tspeed: 0.1437s/iter; left time: 368.0148s\n",
            "\titers: 200, epoch: 1 | loss: 0.8747768\n",
            "\tspeed: 0.0694s/iter; left time: 170.8397s\n",
            "Epoch: 1 cost time: 26.029104709625244\n",
            "Epoch: 1, Steps: 266 | Train Loss: 0.9020743 Vali Loss: 1.5408937 Test Loss: 1.7541547\n",
            "Validation loss decreased (inf --> 1.540894).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.5427865\n",
            "\tspeed: 0.2051s/iter; left time: 470.7698s\n",
            "\titers: 200, epoch: 2 | loss: 0.5512825\n",
            "\tspeed: 0.0710s/iter; left time: 155.8516s\n",
            "Epoch: 2 cost time: 19.415918111801147\n",
            "Epoch: 2, Steps: 266 | Train Loss: 0.6356441 Vali Loss: 1.4129847 Test Loss: 1.5737388\n",
            "Validation loss decreased (1.540894 --> 1.412985).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.5384642\n",
            "\tspeed: 0.1773s/iter; left time: 359.6514s\n",
            "\titers: 200, epoch: 3 | loss: 0.5318101\n",
            "\tspeed: 0.0721s/iter; left time: 139.1376s\n",
            "Epoch: 3 cost time: 19.638471364974976\n",
            "Epoch: 3, Steps: 266 | Train Loss: 0.5568858 Vali Loss: 1.3069046 Test Loss: 1.4934905\n",
            "Validation loss decreased (1.412985 --> 1.306905).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.5138255\n",
            "\tspeed: 0.1799s/iter; left time: 317.1932s\n",
            "\titers: 200, epoch: 4 | loss: 0.4908907\n",
            "\tspeed: 0.0733s/iter; left time: 121.8681s\n",
            "Epoch: 4 cost time: 19.921699285507202\n",
            "Epoch: 4, Steps: 266 | Train Loss: 0.5353713 Vali Loss: 1.4628005 Test Loss: 1.5948341\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.5108926\n",
            "\tspeed: 0.1802s/iter; left time: 269.7838s\n",
            "\titers: 200, epoch: 5 | loss: 0.4459175\n",
            "\tspeed: 0.0741s/iter; left time: 103.4989s\n",
            "Epoch: 5 cost time: 20.14570140838623\n",
            "Epoch: 5, Steps: 266 | Train Loss: 0.5254972 Vali Loss: 1.4011228 Test Loss: 1.5562896\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.5514163\n",
            "\tspeed: 0.1822s/iter; left time: 224.2700s\n",
            "\titers: 200, epoch: 6 | loss: 0.5617867\n",
            "\tspeed: 0.0747s/iter; left time: 84.5041s\n",
            "Epoch: 6 cost time: 20.341832160949707\n",
            "Epoch: 6, Steps: 266 | Train Loss: 0.5202828 Vali Loss: 1.3894699 Test Loss: 1.4819934\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            "2\n",
            ">>>>>>>testing : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "test 2857\n",
            "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
            "test shape: (2848, 24, 7) (2848, 24, 7)\n",
            "mse:1.49349045753479, mae:0.9278024435043335\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot"
      ],
      "metadata": {
        "id": "JzsdzOBEZmhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom data: xxx.csv\n",
        "# data features: ['date', ...(other features), target feature]\n",
        "\n",
        "# we take ETTh2 as an example #模仿informer 的 colab example的custom_dataset与predict部分\n",
        "import pandas as pd\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path = 'ETTh2.csv'\n",
        "\n",
        "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
      ],
      "metadata": {
        "id": "ITsBvf3CZrKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.do_predict = True\n",
        "if args.do_predict:\n",
        "    print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    prediction=exp.predict(setting, True)#data_factory做好了pred里面的batch_size=1的情况，是autoformer在informer基础之上做的\n",
        "    torch.cuda.empty_cache()\n",
        "    print('>>>end>>>>')"
      ],
      "metadata": {
        "id": "c0NgpX76cK2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7d036a-4c41-4775-b851-060f66df9354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>predicting : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "pred 1\n",
            ">>>end>>>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "setting"
      ],
      "metadata": {
        "id": "t8Kr9FozffdW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a259192b-074a-4703-a56d-c5d7af29d3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "5_jTxIgOclvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99ead4c-d010-4155-fa4c-ad937e7be857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.55201644 -0.14547308 -0.14696065  0.72414106  0.979641\n",
            "    1.2544575  -0.16230269]\n",
            "  [ 1.6824205   0.00898075 -0.23358944  0.5187563   1.0084326\n",
            "    1.3392131  -0.13548324]\n",
            "  [ 1.9432167   0.00673942 -0.21658507  0.49259612  0.9980917\n",
            "    1.3379982  -0.13066034]\n",
            "  [ 2.1077955  -0.01110016 -0.20550445  0.47408536  1.0058566\n",
            "    1.3468906  -0.13925606]\n",
            "  [-1.9111942  -0.00482636 -0.38156134  0.95145494  1.0468662\n",
            "    1.1666466  -0.25394207]\n",
            "  [-1.9085716  -0.01319293 -0.38271782  0.93840843  1.0400066\n",
            "    1.1684406  -0.25587082]\n",
            "  [-1.8947557  -0.02553644 -0.37368754  0.92090696  1.029063\n",
            "    1.1596617  -0.24878338]\n",
            "  [-1.86093    -0.03703598 -0.35777962  0.90065676  1.0216465\n",
            "    1.146143   -0.23917386]\n",
            "  [-1.7916617  -0.03926937 -0.34309727  0.88366985  1.0203441\n",
            "    1.1375666  -0.23842448]\n",
            "  [-1.6844658  -0.02881484 -0.33429092  0.86980575  1.0193781\n",
            "    1.1421032  -0.24814793]\n",
            "  [-1.551528   -0.01234733 -0.33372465  0.8556962   1.0138927\n",
            "    1.1623943  -0.25731176]\n",
            "  [-1.4073591   0.0021633  -0.3409961   0.8381359   1.0031893\n",
            "    1.1880672  -0.26009372]\n",
            "  [-1.2509143   0.01087427 -0.34806463  0.8101956   0.9881603\n",
            "    1.2032933  -0.25805208]\n",
            "  [-1.0640625   0.0079205  -0.3449081   0.7701376   0.97148794\n",
            "    1.2033852  -0.24459407]\n",
            "  [-0.82806    -0.00557222 -0.33171847  0.72915405  0.95546925\n",
            "    1.1969998  -0.21666835]\n",
            "  [-0.5563695  -0.01551188 -0.31471565  0.69708604  0.9408626\n",
            "    1.193008   -0.1918307 ]\n",
            "  [-0.2738558  -0.01486102 -0.30102637  0.6704626   0.9285224\n",
            "    1.1955485  -0.18770514]\n",
            "  [ 0.00681758 -0.01060783 -0.29927084  0.6427492   0.91700315\n",
            "    1.2044775  -0.20141691]\n",
            "  [ 0.27428773 -0.0075325  -0.30804747  0.6135968   0.9050137\n",
            "    1.2130537  -0.21688843]\n",
            "  [ 0.503548   -0.00828118 -0.31285834  0.5856447   0.8978635\n",
            "    1.2133293  -0.22106814]\n",
            "  [ 0.68778276 -0.02083102 -0.30665287  0.56155664  0.9008733\n",
            "    1.2080152  -0.20990235]\n",
            "  [ 0.8527304  -0.03288116 -0.29502395  0.5492725   0.91161877\n",
            "    1.209355   -0.18646526]\n",
            "  [ 1.0010773  -0.0021225  -0.28107944  0.5588743   0.9246225\n",
            "    1.2164621  -0.16503352]\n",
            "  [ 0.59324664  0.02962382 -0.3860414   0.58735234  0.91865647\n",
            "    1.2383057  -0.21073052]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "#预测OT\n",
        "plt.plot(prediction[-1,:,-1])#由于prediction.shape是[1,24,7]那么batch只有1 索引只能是0或-1 都是代表batch这一维本身\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "plt.plot(prediction[0,:,-1])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "# draw HUFL prediction\n",
        "plt.plot(prediction[0,:,0])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UyQ5MQyGcYWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "8f00b1df-166e-4f35-9864-802443a5197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 24, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 24, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 24, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU1b3H8c8vySRMCJkAYd83d0A0BNRatWrdqty6tKJWQDFt1d7a7V672tp7bxdb27pUC4KgVdEuCFase9VWgUQF2RTCToAQCAkhC1nm3D8yYKQJ20zmeTLzfb9eeWXmmSdzzmsYvjk5c57fMeccIiKS+FK87oCIiMSHAl9EJEko8EVEkoQCX0QkSSjwRUSSRJrXHTiU3NxcN3jwYK+7ISLSYbz77rs7nXM9WnvM14E/ePBgioqKvO6GiEiHYWYb23pMUzoiIklCgS8ikiQU+CIiSUKBLyKSJBT4IiJJQoEvIpIkFPgiIklCgR9nO6rqeLpwE01hlaUWkfjy9YVXiaQp7Hhi0UbuefEjquoaGdAtkzOH5XrdLRFJIgr8OFi6uYIfPLucZSWVnNgnm1Xb9lBR0+B1t0QkyUQ9pWNmA8zsdTNbaWYrzOzrrZxjZnafmRWb2Qdmdlq07XYElbUN/ODZZfzH7/9F6Z467p84hpmT8w48JiIST7EY4TcC33LOvWdmXYB3zexl59zKFudcAoyIfI0DHop8T0jOOZ5dUsL/Pr+K8up6Jp0xmG9+9jiyOwWoqW8E0AhfROIu6sB3zm0DtkVuV5nZKqAf0DLwJwCPueYNdBeaWY6Z9Yn8bEJZU1rFD55dzqL15Zw6IIdZU/I5pV/owOPBQCqBVNMIX0TiLqZz+GY2GBgDLDrooX7A5hb3t0SOJUzg19Y3cd9ra5j+5jo6Z6Txf58fybVjB5CSYp84z8wIBQMKfBGJu5gFvpllAX8B7nDO7YnieQqAAoCBAwfGqHft6+WVpfx4/gpKKmq5+vT+3HnJCeRmZbR5fnYwwB4FvojEWUwC38wCNIf9E865v7ZySgkwoMX9/pFj/8Y5Nw2YBpCXl+frxeqle+r4/tzlvLKqlON6ZfHMl88gf0i3w/6cRvgi4oWoA9/MDJgBrHLO3dvGafOB281sDs0f1lZ29Pn7zeU1XPfIQnZW1fPdS07gpk8NIZB6ZIueQsEAu/bWt3MPRUQ+KRYj/LOALwHLzGxJ5Nj3gIEAzrmHgQXApUAxUANMiUG7ntmws5rrH1lEVV0DcwrGM3pAzlH9fE4wwLqy6nbqnYhI62KxSuefgB3mHAfcFm1bflC8Yy/XP7KQ+sYwTxWM5+S+ocP/0EFCwQAVNRrhi0h86Urbo/Dh9j3c8MgiwJhTcAbH9+5yTM8TCgao2tdIOOz+bRWPiEh7UfG0I7S8pJJrpy0kNcV4+svjjznsoXmVjnNQVdcYwx6KiByaAv8IvL9pN9dNX0jn9DSe+fIZDOuRFdXzhYIBQOUVRCS+NKVzGIUbypnyaCHds9J5Yuo4+nfNjPo5Ffgi4gUF/iG8XbyTm2cX0SenE09OHU/vUKeYPK8CX0S8oCmdNryxuowpswoZ2C2TpwvOiFnYA+RkpgMKfBGJL43wW/HKylJufeI9hvfM4o9Tx9Gtc3pMn18jfBHxgkb4B3lh2Ta+8sd3ObFPF566ZXzMwx4+DvyKWq3FF5H40Qi/hXlLSvjmM0sZMyCHR6eMpUunQLu00ymQQnpqikb4IhJXGuFHzF+6lTueXsLYwV2ZfVN+u4U9NJdIVsVMEYk3jfAjHnhtDSf1yebRyfkE01Pbvb1QME0jfBGJK43wgd3V9awu3cslp/SOS9iDSiSLSPwp8IGijbsBGDv48LXsYyUnM12BLyJxpcCn+Wra9NSUoy5zHA2N8EUk3hT4wOL15YzqH6JTID7TObC/RLICX0TiJ+kDv6a+keUllYw9gq0JYyk7GKCqrpGmsK93cRSRBBKTwDezmWa2w8yWt/H4uWZWaWZLIl8/ikW7sbBkcwWNYUd+HOfv4eOLr6rqNMoXkfiI1Qh/FnDxYc55yzl3auTr7hi1G7XC9bsxg9MGdY1ruyqvICLxFpPAd869CZTH4rnirXBDOcf36nIggONFgS8i8RbPOfwzzGypmb1gZie3dZKZFZhZkZkVlZWVtWuHGpvCvLdpN/lxnr8HBb6IxF+8Av89YJBzbjRwP/BsWyc656Y55/Kcc3k9evRo106t2LqHmvqmuK6/3y8nU4EvIvEVl8B3zu1xzu2N3F4ABMwsNx5tH0rhhuZZKI3wRSQZxCXwzay3mVnkdn6k3V3xaPtQFq8vZ2C3THplx25zkyN1oESy1uKLSJzEpHiamT0FnAvkmtkW4C4gAOCcexi4GviqmTUCtcC1zjlPF6A75yjauJvzju/pSfudAqmkp6WoYqaIxE1MAt85N/Ewjz8APBCLtmJlbdleyqvryR8S3+WYLam8gojEU9Jeabt4ffwLph1MgS8i8ZS0gV+4oZzcrHSG5Hb2rA8KfBGJp6QN/MXryxk7uBuRz5I9kaPAF5E4SsrA31pRS0lFrafTOaARvojEV1IGvpfr71vKDgao1LJMEYmTpA38rIw0TuyT7Wk/QsEAVftUIllE4iM5A3/9bk4b1JXUFO/m7+Hji6+0Fl9E4iHpAr+ipp6PSqvIH+zd+vv9VF5BROIp6QK/aIP36+/3U+CLSDwlXeB7sWF5W0KqmCkicZR0gb94Q/w3LG9Ljkb4IhJHSRX4tfVNLNtSSZ4PpnOgRcVMBb6IxEFSBf77m3c3b1juYcG0lrK1SkdE4iipAn//huWnD/LHCL9TIJWMtBRN6YhIXCRX4Hu0YfmhhHS1rYjESdIEvpcblh+K6umISLzEJPDNbKaZ7TCz5W08bmZ2n5kVm9kHZnZaLNo9Gl5uWH4oCnwRiZdYjfBnARcf4vFLgBGRrwLgoRi1e8T8UjDtYDmZCnyRRBUOO8I+qpUVk8B3zr0JlB/ilAnAY67ZQiDHzPrEou0j5eWG5YeSrRG+SMJpbArz5KJNjPvZq3z1iXfxeAvvA+I1h98P2Nzi/pbIsX9jZgVmVmRmRWVlZTFpfP+G5X6bzgFN6YgkEuccr64q5eLfvcX35i4jGEjlxRWlzH2/xOuuAT780NY5N805l+ecy+vRo0dMnnNtWbXnG5a3JRQMsHdfI41NYa+7IiJRWLalkonTF3Lz7CKawo6Hbzid1799LnmDuvKT51ayY0+d112MW+CXAANa3O8fORYX++fv/TrCB9hT1+hxT0TkWGwur+Hrc97n8gf+yerSvdw94WRe+sanufiU3qSmGL+4ehR1DU384Nnlnk/tpMWpnfnA7WY2BxgHVDrntsWpbQrXe79heVtaVszs1jnd496IyJGqrG3g968X8+jbGzDg1nOH8ZVzh5Hd6ZPX+QzrkcU3LzyOn73wIc99sI0rRvf1psPEKPDN7CngXCDXzLYAdwEBAOfcw8AC4FKgGKgBpsSi3SO1eIP3G5a3RSWSRTqW+sYwjy/cyP2vraGytoErx/TnW589jr45wTZ/ZurZQ1mwfDt3zVvOmcO6k5uVEccefywmge+cm3iYxx1wWyzaOlrbKmvZsruWm84a4kXzh5WjEskiHYJzjueXbeOXf/+ITeU1nD0ilzsvOYGT+4YO+7OpKcavrh7FZff9k7vmreDB6+N+KRIQvykdzyxe78/19/tphC/if8tLKvnhvOW8v6mCE3p3YfZN+Zxz3NEtKhnRqwtfv2AE97z4EZ9bto1LRsZ1ZTqQBIHvlw3L27K/YmZlTb3HPRGRg+2pa+Del1bz2Dsb6NY5g19eNYqrTu9/zPthF3x6KC8s38YP5y1n3NDucf/cznfLMmPNLxuWt0UjfBH/cc7x3NKtXPDrN5j9zgZuGD+IV791Dl8YOyCqLAmkpnDP1aOprG3g7udWxK7DRyihR/j7Nyy/fHT8/3Q6UhlpqXQKqESyiF+s31nNj+Yt5601OxnZL8T0G/NiuiXqiX2yue284fz2lTV8blRfLjipV8ye+3ASOvD3b1julx2u2qKrbUW8V9fQxO//sZaH/7GWjLQU7p5wMtePG9QuswO3njucvy/fzvfmLmPs4G4H9rdubwk9pVO4oZxAqnGqDzYsPxQFvoi33lhdxkW/fZP7Xl3DJSN78+q3z+HGMwa321RweloKv7pmNLuq6/np8yvbpY3WJPQIv3nD8hxfbFh+KAp8EW9sr6zjp39byfPLtjE0tzNPTB3HWcNz49L2Kf1CfPWcYTzwejGXjerDecf3bPc2E3aEv3/Dcj+WUzhYKJhOZa1KK4jES2NTmBn/XM8F977BK6tK+daFx/HCHWfHLez3+9r5wxnRM4vv/XUZe+raf9CXsIG/ZHOFrzYsP5RQMKCNzEXiZHlJJVc88C9++reV5A3uysvfOIevnT+CjLT4zwRkpKVyzzWjKd1Tx88WrGr39hJ2SqdwQ7mvNiw/lFAwQIXW4Yu0q8amML//x1rue3UN3Tqn89D1p3HxKb09L7ly6oAcbjl7KH94cx2XjezLp0a0318ZCTvC9+OG5W0JBQNU1zfRoBLJIu1ibdlernr4He59eTWXjuzDS9/4NJeM7ON52O/3jQuPY2huZ/77Lx9Qva/9pncTMvAbm8K8t9F/G5a3JRRs/kNL0zoisRUOOx7913ou/d1bbNxVzQPXjeG+iWPIyfRXZdpOgVTuuWYUWytr+cXfP2y3dhJySmfltj1U+3DD8raEWhRQ6+5RFT2RRLNldw3f+dMHvLNuF585oSc/v3IkPX22xWlLpw/qxpQzhzDzX+u5dGQfxg/tHvM2EnKE7/eCaQdTeQWR2HHO8UzRZi7+7Vt8sKWCX1w1khmT8nwd9vt956LjGdQ9k//+ywfU1jfF/PkTcoRfuMGfG5a3JRRs/vNSgS8SnbKqfXz3r8t4ZVUp+UO68etrRjOgW6bX3TpiwfRUfnnVKNbs2EtGWuzH4zF5RjO72Mw+MrNiM7uzlccnm1mZmS2JfE2NRbutcc5RtMGfG5a3RSN8kei9sGwbF/32Td5cU8YPLjuRObeM71Bhv9+4od25YfwgUtrhKt+oR/hmlgo8CFwIbAEKzWy+c+7g64Wfds7dHm17h1PfFGbq2UM5pZ8/yyG3RoEvcuwqaxq4a/5ynl2ylZH9Qtz7hdGM6NXF6275UiymdPKBYufcOoDIvrUTgPgViGghIy2Vr547zIumj9mBwK9R4IscjUXrdvH1OUso27uPOy4YwW3nDSeQmpAfTcZELF6ZfsDmFve3RI4d7Coz+8DM/mxmA9p6MjMrMLMiMysqKyuLQff8Lz0thWAgVSN8kaPwp6LN3DBjEZnpqcy99UzuuOA4hf1hxOvVeQ4Y7JwbBbwMzG7rROfcNOdcnnMur0ePo9tCrCNTATWRIxMOO+558UO+8+cPyB/Sjbm3ncWo/v6uiOsXsZjSKQFajtj7R44d4Jzb1eLuI8AvY9BuQlHgixxeXUMT33pmKc8v28bE/AHcPeEUjeqPQiwCvxAYYWZDaA76a4HrWp5gZn2cc9sid68A2r9KUAcTylTgixxKWdU+bnmsiKVbKvjepSdwy9lDfVMaoaOIOvCdc41mdjvwIpAKzHTOrTCzu4Ei59x84D/N7AqgESgHJkfbbqIJBQNsLq/xuhsivvTR9ipumlXIrup9PHT96Vx8Sm+vu9QhxeTCK+fcAmDBQcd+1OL2d4HvxqKtRBUKBlihEb7Iv3ljdRm3P/EewfRU/vTlMxnZP+R1lzqshLzStiMKBQNUKPBFPuGPCzdy1/wVjOiZxczJY+mbE/S6Sx2aAt8nQsEANZESyfoQSpJdU9jxfwtWMeOf6/nMCT25b+IYsjIUV9HSK+gTLa+2zVXFTEli1fsa+fqcJbyyqpTJZw7mh587qd02E082CnyfUOCLwLbKWm6eVcSH2/fwkytOZtKZg73uUkJR4PuE6ulIslteUsnNswvZW9fIjMljOe/4nl53KeEo8H2i5SYoIsnm/U27uXHGYrp0SuPPXz2TE/t0nOKHHYkC3yf2j/C1zaEkm/c27WbSjMV0y0rnqVvGayVOO1Lg+8T+wK9QxUxJIu9u3M2kmYvpnpXOnILx9Akp7NuTAt8nNIcvyebdjeVMmllIblY6cwrOoHeoY+xQ15FpwbdPBFJTyExXiWRJDkUbyrlxxmJ6dMlQ2MeRAt9HVDFTkkHhhnImzVxMr+xOzCkYr7CPIwW+jyjwJdEtXh8J+1AnnioYT69shX08aQ7fRxT4ksgWrdvFlFmF9Al14qlbxtNTYR93GuH7SCgY0LJMSUgL1+1i8qORsC9Q2HtFI3wfCQUDWpYpCeedtbu4aVYh/boGeeqW8fTootIhXtEI30c0pSOJ5u21O5kyazH9Ffa+EJPAN7OLzewjMys2sztbeTzDzJ6OPL7IzAbHot1EEwoGqG1oor4x7HVXRKL2dvFObppVyMBumTxVoLD3g6gD38xSgQeBS4CTgIlmdtJBp90M7HbODQd+A/wi2nYTkerpSKL4V/FOpswqZFC3zjx5y3hVgPWJWIzw84Fi59w651w9MAeYcNA5E4DZkdt/Bs437T78b3S1rSSChet2cfPsQobkdubJW8Yp7H0kFoHfD9jc4v6WyLFWz3HONQKVQPfWnszMCsysyMyKysrKYtC9jiNbgS8d3HubdnPTrEL6d83kianj6K6w9xXffWjrnJvmnMtzzuX16NHD6+7EVY4qZkoHtrykkkkzm8slPKmw96VYBH4JMKDF/f6RY62eY2ZpQAjYFYO2E4qmdKSjWl1axY0zF5PdKcATU8dpnb1PxSLwC4ERZjbEzNKBa4H5B50zH5gUuX018JpzzsWg7YTycYnkeo97InLk1u+s5vpHFpGWYjwxdRz9u2Z63SVpQ9QXXjnnGs3sduBFIBWY6ZxbYWZ3A0XOufnADOBxMysGymn+pSAH+XgOv9HjnogcmS27a7h++kKawo6nC8YzOLez112SQ4jJlbbOuQXAgoOO/ajF7Trgmli0lcgCqSl0Volk6SBK99Rx3fRF7N3XyFMF4xnRq4vXXZLD8N2HtslOV9tKR7Bz7z6um76QXXv3MfumfE7uG/K6S3IEVEvHZ7IV+OJzFTX1fGnGYkoqapk9JZ8xA7t63SU5Qhrh+0xOpipmin9V1TUw6dFC1u7Yy7Qv5TFuaKuX04hPKfB9RlM64le19U3cPKuIFSWVPHj9aXz6uOS6TiYRKPB9JhQMUFGrZZniL3UNTRQ8XkTRxnJ+88VTufCkXl53SY6B5vB9RiN88ZuGpjC3P/keb63ZyT1Xj+Ly0X297pIcI43wfSYUDFDXEGZfY5PXXRGhKey44+klvLJqBz+dcDLX5A04/A+JbynwfUblFcQvwmHHf//lA57/YBvfu/QEvnTGYK+7JFFS4PtMtgqoiQ845/jxcyv487tbuOOCERR8epjXXZIYUOD7TE5mOqARvnjHOccv/v4Rj72zkYJPD+Xr54/wuksSIwp8n9GUjnjtwdeLefiNtVw/biDfveQEtFdR4lDg+4wCX7w045/r+dVLq7lyTD9+OuEUhX2CUeD7zMclkhX4El9zFm/ip39bySWn9OaXV48iJUVhn2gU+D6T3an50giN8CWe5i0p4btzl3Hu8T343bVjSEtVNCQi/av6TFpqClkZaQp8iZuXVmznm88sZdyQbjx8w+mkpykWElVU/7Jm1s3MXjazNZHvrZbNM7MmM1sS+Tp4Nyw5iK62lXh5c3UZtz/5PiP7hXhk0lg6BVK97pK0o2h/ld8JvOqcGwG8Grnfmlrn3KmRryuibDPhZQdVMVPa3+L15RQ8XsSwnlnMnpJPVoYqrSS6aAN/AjA7cns28B9RPp8AORrhSzv7YEsFN80qpF9OkMdvzieUGfC6SxIH0QZ+L+fctsjt7UBbJfQ6mVmRmS00M/1SOAxN6Uh7+nD7Hm6cuZiunQM8MXU8uVkZXndJ4uSwf8OZ2StA71Ye+n7LO845Z2aujacZ5JwrMbOhwGtmtsw5t7aN9gqAAoCBAwcernsJKRQMaFmmtIt1ZXu54ZHFdEpL5cmp4+kd6uR1lySODhv4zrkL2nrMzErNrI9zbpuZ9QF2tPEcJZHv68zsH8AYoNXAd85NA6YB5OXltfULJKGFMjXCl9jbXF7DDY8swjnHH6eOZ0C3TK+7JHEW7ZTOfGBS5PYkYN7BJ5hZVzPLiNzOBc4CVkbZbkILBQPsawxT16ASyRIbJRW1TJy+kL37Gnn85nEM75nldZfEA9EG/s+BC81sDXBB5D5mlmdmj0TOOREoMrOlwOvAz51zCvxDUMVMiaWtFbVMnLaQytoGnpg6npP6ZnvdJfFIVOuwnHO7gPNbOV4ETI3cfhsYGU07yaZlPZ2e2ZpjlWO3rbJ5ZL+7up4/Th3HyP4hr7skHtIldT6UowJqEgPbK+u4bvoiyvfW89jN+YwekON1l8RjutLCh1QxU6JVuqeO66YvpKxqH7NvymfMwFYvgpckoxG+D6lipkRjx546Jk5fSOmeOmbfNJbTBynspZlG+D6kEb4cq7KqfUycvpDtlXXMvimf0wd187pL4iMa4ftQtgJfjsHOvfu4bvpCtlbU8ejksYwdrLCXT1Lg+1BqitFFJZLlKOyKhP2W3bU8OmUs44Z297pL4kMKfJ9SxUw5UuXV9Vz/yCI2ldcwY3Ie4xX20gYFvk/lqLyCHIHd1fVcN30h63dWM2PSWM4clut1l8TH9KGtT6liphxORU3zyH7dzmpmTMrjrOEKezk0jfB9SoEvh7I/7IvL9jL9xjzOHtHD6y5JB6ARvk+FggEqFPjSiu2VdUx+dDHryqqZduPpnHOcwl6OjALfpzTCl9Z8uH0PUx4tpKqukRmTNbKXo6PA96nsYID6SIlkbSwtAP8q3slXHn+XzIxUnvnyGap6KUdNc/g+pattpaW/vreFyY8upm9OkLm3nqWwl2OiwPcpBb4AOOd44LU1fPOZpYwd3I1nvnIGfXOCXndLOihN6fhUTqYCP9k1NIX54bPLmVO4mSvH9OPnV40iPU1jNDl2Ub17zOwaM1thZmEzyzvEeReb2UdmVmxmd0bTZrI4MMJXxcyktHdfI1NnFzGncDNf+8xwfv2F0Qp7iVq0I/zlwJXAH9o6wcxSgQeBC4EtQKGZzdc2h4d2oESyRvhJZ8eeOqbMKuTD7VX87MqRTMwf6HWXJEFEu8XhKgAzO9Rp+UCxc25d5Nw5wAS0kfkhaQ4/Oa0prWLyo4XsrqnnkUl5nHd8T6+7JAkkHn8j9gM2t7i/JXKsVWZWYGZFZlZUVlbW7p3zqy6dFPjJZuG6XVz10NvUN4V55stnKOwl5g47wjezV4DerTz0fefcvFh3yDk3DZgGkJeX52L9/B1FaorRpVOaKmYmiXlLSvjOnz5gYPdMZk0ZS/+umV53SRLQYQPfOXdBlG2UAANa3O8fOSaHoattE1847HjojbXc8+JHjBvSjWlfyiMUWaElEmvxWJZZCIwwsyE0B/21wHVxaLfDU4nkxLa1opZv/2kpb6/dxRWj+3LPNaPISNNV1dJ+ogp8M/s8cD/QA3jezJY45y4ys77AI865S51zjWZ2O/AikArMdM6tiLrnSUAj/MTknGPekq38cN5ymsKOn185ki+OHXC4xQ8iUYt2lc5cYG4rx7cCl7a4vwBYEE1bySgUDFC6Z6/X3ZAYqqip5/vPLuf5D7Zx+qCu3PuF0Qzq3tnrbkmS0JW2PhYKBqjQhVcJ443VZXznT0spr67nOxcdz1fOGUZqikb1Ej8KfB/bv6+tc05/7ndgtfVN/OyFVTz2zkZG9Mxi5uSxnNIv5HW3JAkp8H0sFAxQ3xSmriFMMF0f5nVESzdX8I2nl7BuZzU3f2oI37noeJW7Fs8o8H2s5dW2CvyOpaEpzIOvF3P/a8X07JLBk1PHcab2nBWPKfB9rGXg9w518rg3cqTWle3lG88sZenmCj4/ph8/vuLkA/+WIl5S4PtYTjAdUHmFjiIcdjyxaCP/u2AVGWmpPHDdGD43qq/X3RI5QIHvYyqg1nG8t2k3P5m/gqVbKjl7RC6/umY0vbL1V5n4iwLfxw6USK6p97gn0pbSPXX84oUP+ev7JfTsksG9XxjN58f006oq8SUFvo9phO9fdQ1NzPzXeh54rZjGJset5w7jtvOG0zlD/6XEv/Tu9LEundIwQxUzfcQ5x8srS/mf51exqbyGC0/qxQ8uO1FXy0qHoMD3sZQUo0tGmkb4PrGmtIq7/7aSt9bsZETPLB6/OZ+zR/TwulsiR0yB73MhVcz0XGVNA799dTWPvbORzump3HX5SdwwfhCBVO0xKx2LAt/ncoLpCnyPNIUdcwo38euXVlNRU8/E/IF888Lj6J6V4XXXRI6JAt/nVCLZG28X7+R/nl/Fym17yB/SjbsuP4mT+6r+jXRsCnyfCwUDbK2s9bobSWN5SSW/+PuHvLVmJ/1ygjxw3RguG9lHyywlISjwfW5/xUxpXxt3VfOrl1bz3NKt5GQG+MFlJ3LD+EEqdCYJJdodr64BfgycCOQ754raOG8DUAU0AY3Oubxo2k0m+6d0VCK5feyoquP+V4t5avEmAqkp3H7ecArOGUp2J9W+kcQT7Qh/OXAl8IcjOPc859zOKNtLOqFggIYmR21DE5np+oMsVqrqGpj25jpm/HM9+xrDTMwfwH9+ZgQ9VQ5BEli0WxyuAjTybEctr7ZV4EdvX2MTf1y4iQdfL6a8up7LRvXh2589niG5unBKEl+8EsQBL5mZA/7gnJvW1olmVgAUAAwcODBO3fOvnMyPA79PKOhxbzquprDj2fdLuPfl1ZRU1PKp4bn818XHM6p/jtddE4mbwwa+mb0C9G7loe875+YdYTufcs6VmFlP4GUz+9A592ZrJ0Z+GUwDyMvLc0f4/AnrwAhfe9sek/2lEH790mo+Kq3ilH7Z/PyqkbpCVpLSYQPfOXdBtI0450oi33eY2VwgH2g18OWTVEDt2ITDjpdWlnLfq2tYuW0Pg7pncv/E5iWWKdo4XJJUu0/pmFlnIMU5VxW5/Vng7vZuN1EcKJGswL6pOsMAAAenSURBVD8i4bDj7yu2c9+ra/hwexWDu2fyq2tGM+HUviqFIEkv2mWZnwfuB3oAz5vZEufcRWbWF3jEOXcp0AuYG/lgNw140jn39yj7nTSyI4GvtfiH1hR2LFi2jftfW8Pq0r0M7dGZ33xxNJeP6kuagl4EiH6VzlxgbivHtwKXRm6vA0ZH004y65LRXCJZUzqtawo7nlu6lftfW8PasmqG98zid9eeyudG9SVVUzcin6B1fj6XkmJkd1I9nYM1NoWZt2QrD75ezLqd1RzfqwsPXDeGS0/RHL1IWxT4HYAKqH2soSnM3PdLePD1YjbuquGE3l146PrTuOjk3gp6kcNQ4HcAOaqJz7bKWp4p3MLThZvYWlnHyX2z+cOXTufCE3sp6EWOkAK/A0jWEX5T2PGPj3bw1OJNvPbhDsIOzh6Ry90TTuH8E3vqCm+Ro6TA7wCygwFKdidPieStFbU8XbiZZ4o2s62yjtysDL5yzjCuHTuQgd0zve6eSIelwO8AkmGE39gU5h8flfHk4k3846MdOODsET246/KTOP/EXlpDLxIDCvwOIJFLJJfsH80Xbmb7njp6dMng1nOH88WxAxjQTaN5kVhS4HcAoWCAxrCjpr6Jzhkd+58sHHZ8uL2Kt9fu5M01O3lrTRkA5xzXg59MOJnPnNBTo3mRdtKx0yNJtKyn09EC3znHup3VvL12F++s3ck7a3exO1IIbkhuZ7523nC+MHYA/btqNC/S3jpWeiSpnBaB3zfH/yWSt+yuiQT8Lt5eu5PSPfsA6BvqxPkn9uLMYd05Y1h3lXsWiTMFfgfg14qZzjkqaxvYsruW4h17mwN+3U42lzevKMrNSueMYbmcOaw7Zw7rzsBumQn3GYRIR6LA7wCyPQp85xx7ahvZvLuGLbtr2fJv32vZu6/x4352SmP80O7cfNYQzhyey4ieWQp4ER9R4HcA0WyC4lzzh73V+xrZu6+R6n1Nke/N9/ffbr7fxN59DZRXN7Bldw0lu2upahHoAFkZafTvGqR/10zGD+1O/65BBnTLZGC3TI7r1UUFy0R8TIHfAYQi2xz+8sUPeeiNtTSFHWHnCIcdYQdNzuGcixwnctzR5Bz1jWHCR7BvmBl0Tk+jc0YqOcF0+ncNHgj0/QHfv2uQUDCgUbtIB6XA7wC6ZKRx67nD2FheQ6oZKdZcRTPFrPl+CqRY5H6KYUbkuJGRlkLnjDQ6Z6SRlZFKVkaAzhmpZB041vwVDKSqJo1Igot2A5R7gMuBemAtMMU5V9HKeRcDvwNSad4Y5efRtJtszIz/uvgEr7shIh1ctFe4vAyc4pwbBawGvnvwCWaWCjwIXAKcBEw0s5OibFdERI5SVIHvnHvJObf/U72FQP9WTssHip1z65xz9cAcYEI07YqIyNGL5TXsNwEvtHK8H7C5xf0tkWOtMrMCMysys6KysrIYdk9EJLkddg7fzF4Berfy0Pedc/Mi53wfaASeiLZDzrlpwDSAvLy8I1hfIiIiR+Kwge+cu+BQj5vZZOBzwPnOudYCugQY0OJ+/8gxERGJo6imdCKrb/4LuMI5V9PGaYXACDMbYmbpwLXA/GjaFRGRoxftHP4DQBfgZTNbYmYPA5hZXzNbABD5UPd24EVgFfCMc25FlO2KiMhRimodvnNueBvHtwKXtri/AFgQTVsiIhIda33a3R/MrAzYeIw/ngvsjGF3Oiq9Ds30OjTT69AskV+HQc65Hq094OvAj4aZFTnn8rzuh9f0OjTT69BMr0OzZH0dtJeciEiSUOCLiCSJRA78aV53wCf0OjTT69BMr0OzpHwdEnYOX0REPimRR/giItKCAl9EJEkkXOCb2cVm9pGZFZvZnV73x0tmtsHMlkWugi7yuj/xYmYzzWyHmS1vcaybmb1sZmsi37t62cd4aON1+LGZlUTeE0vM7NJDPUciMLMBZva6ma00sxVm9vXI8aR7TyRU4GuzlVad55w7NcnWHM8CLj7o2J3Aq865EcCrkfuJbhb//joA/Cbynjg1chV8omsEvuWcOwkYD9wWyYWke08kVOCjzVYEcM69CZQfdHgCMDtyezbwH3HtlAfaeB2SjnNum3PuvcjtKpprevUjCd8TiRb4R7XZShJwwEtm9q6ZFXjdGY/1cs5ti9zeDvTysjMeu93MPohM+ST8NEZLZjYYGAMsIgnfE4kW+PJJn3LOnUbzFNdtZvZprzvkB5F9G5J1PfJDwDDgVGAb8GtvuxM/ZpYF/AW4wzm3p+VjyfKeSLTA12YrLTjnSiLfdwBzaZ7ySlalZtYHIPJ9h8f98YRzrtQ51+ScCwPTSZL3hJkFaA77J5xzf40cTrr3RKIFvjZbiTCzzmbWZf9t4LPA8kP/VEKbD0yK3J4EzPOwL57ZH3ARnycJ3hNmZsAMYJVz7t4WDyXdeyLhrrSNLDP7LZAKzHTO/a/HXfKEmQ2leVQPzfsePJksr4WZPQWcS3MJ3FLgLuBZ4BlgIM0lt7/gnEvoDzTbeB3OpXk6xwEbgC+3mMdOSGb2KeAtYBkQjhz+Hs3z+Mn1nki0wBcRkdYl2pSOiIi0QYEvIpIkFPgiIklCgS8ikiQU+CIiSUKBLyKSJBT4IiJJ4v8BM2RjokZC4ZkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try"
      ],
      "metadata": {
        "id": "veiY5xDj5nYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp.train(setting)"
      ],
      "metadata": {
        "id": "_6YDJ0TC4nyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path=args.root_path\n",
        "data_path=args.data_path\n",
        "print(\"root_path:\", root_path)\n",
        "print(\"data_path:\", data_path)\n",
        "print(\"[args.seq_len, args.label_len, args.pred_len]:\", [args.seq_len, args.label_len, args.pred_len])\n",
        "print(\"args.features:\", args.features)\n",
        "print(\"args.target:\", args.target)\n",
        "print(\"args.freq:\", args.freq)\n",
        "\n",
        "data_set, data_loader = data_provider(args, flag='test')"
      ],
      "metadata": {
        "id": "snWDvZfm5gaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set\n",
        "i = 0\n",
        "print(\"data_set:\", data_set)\n",
        "for item in data_loader:\n",
        "  i = i+1\n",
        "  if i < 5:\n",
        "    print(\"item:\", item)\n",
        "    print(\"item size:\", len(item))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KmJCZCAI64eS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}