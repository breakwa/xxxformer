{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1lyx0uUtKvTB",
        "fXWOL3TaKzz2",
        "rn4mhqeGWGbT"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakwa/xxxformer/blob/main/xxxformer_show%20itr%20embedding%20heat%20map.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# requirements.txt"
      ],
      "metadata": {
        "id": "vubyce0ywMHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADN5_hBilzlQ",
        "outputId": "646c043d-8239-4737-8a8c-ea8cf3d312fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install reformer_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvlo2FAMv3qL",
        "outputId": "91553e48-25c7-48a6-da7c-b58f7e0f289c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: reformer_pytorch in /usr/local/lib/python3.7/dist-packages (1.4.4)\n",
            "Requirement already satisfied: product-key-memory in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.1.10)\n",
            "Requirement already satisfied: local-attention in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.5.0)\n",
            "Requirement already satisfied: axial-positional-embedding>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XdEzMXelt5GN"
      },
      "outputs": [],
      "source": [
        "import reformer_pytorch\n",
        "import pandas\n",
        "import sklearn\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igxTD7r-wPoN",
        "outputId": "bdc527a2-25b1-46c9-b6af-8bef9f0ce5b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.utils"
      ],
      "metadata": {
        "id": "PQ9i2_q8TI9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 download data"
      ],
      "metadata": {
        "id": "jXLUb5ZaKldQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    source_url = 'https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/files/?p=%2Fall_six_datasets.zip&dl=1'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    res = requests.get(source_url, headers=headers)\n",
        "\n",
        "    with open('/content/drive/MyDrive/DATA_reformer/datasets.zip', 'wb') as f:\n",
        "        f.write(res.content)\n"
      ],
      "metadata": {
        "id": "Uk-umGQnTuGx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 mask"
      ],
      "metadata": {
        "id": "CK3cRa1YKpV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class TriangularCausalMask():\n",
        "    def __init__(self, B, L, device=\"cpu\"):\n",
        "        mask_shape = [B, 1, L, L]\n",
        "        with torch.no_grad():\n",
        "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n",
        "\n",
        "\n",
        "class ProbMask():\n",
        "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
        "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
        "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
        "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
        "                    torch.arange(H)[None, :, None],\n",
        "                    index, :].to(device)\n",
        "        self._mask = indicator.view(scores.shape).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n"
      ],
      "metadata": {
        "id": "obcQnGROTkA5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 metrics"
      ],
      "metadata": {
        "id": "VPSXrQVJKrbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def RSE(pred, true):\n",
        "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
        "\n",
        "\n",
        "def CORR(pred, true):\n",
        "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)  #.sum(0) axis=0       .mean(0) axis=0 \n",
        "    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n",
        "    return (u / d).mean(-1)\n",
        "\n",
        "\n",
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def RMSE(pred, true):\n",
        "    return np.sqrt(MSE(pred, true))\n",
        "\n",
        "\n",
        "def MAPE(pred, true):\n",
        "    return np.mean(np.abs((pred - true) / true))\n",
        "\n",
        "\n",
        "def MSPE(pred, true):\n",
        "    return np.mean(np.square((pred - true) / true))\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mae = MAE(pred, true)\n",
        "    mse = MSE(pred, true)\n",
        "    rmse = RMSE(pred, true)\n",
        "    mape = MAPE(pred, true)\n",
        "    mspe = MSPE(pred, true)\n",
        "\n",
        "    return mae, mse, rmse, mape, mspe\n"
      ],
      "metadata": {
        "id": "2XbBa4abTZV0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 time features"
      ],
      "metadata": {
        "id": "1lyx0uUtKvTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.tseries import offsets\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "\n",
        "\n",
        "class TimeFeature:   #将dataframe转换为ndarry\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"()\"\n",
        "\n",
        "\n",
        "class SecondOfMinute(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.second / 59.0 - 0.5         # 0-1    --->     (-0.5,0.5)\n",
        "\n",
        "\n",
        "class MinuteOfHour(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.minute / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class HourOfDay(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.hour / 23.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfWeek(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.dayofweek / 6.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfMonth(TimeFeature):\n",
        "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.day - 1) / 30.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfYear(TimeFeature):\n",
        "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
        "\n",
        "\n",
        "class MonthOfYear(TimeFeature):\n",
        "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.month - 1) / 11.0 - 0.5\n",
        "\n",
        "\n",
        "class WeekOfYear(TimeFeature):\n",
        "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
        "\n",
        "\n",
        "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
        "    \"\"\"\n",
        "    Returns a list of time features that will be appropriate for the given frequency string.\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq_str\n",
        "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
        "    \"\"\"\n",
        "\n",
        "    features_by_offsets = {\n",
        "        offsets.YearEnd: [],\n",
        "        offsets.QuarterEnd: [MonthOfYear],\n",
        "        offsets.MonthEnd: [MonthOfYear],\n",
        "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
        "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Minute: [\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "        offsets.Second: [\n",
        "            SecondOfMinute,\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    offset = to_offset(freq_str)\n",
        "\n",
        "    for offset_type, feature_classes in features_by_offsets.items():\n",
        "        if isinstance(offset, offset_type):\n",
        "            return [cls() for cls in feature_classes]\n",
        "\n",
        "    supported_freq_msg = f\"\"\"\n",
        "    Unsupported frequency {freq_str}\n",
        "    The following frequencies are supported:\n",
        "        Y   - yearly\n",
        "            alias: A\n",
        "        M   - monthly\n",
        "        W   - weekly\n",
        "        D   - daily\n",
        "        B   - business days\n",
        "        H   - hourly\n",
        "        T   - minutely\n",
        "            alias: min\n",
        "        S   - secondly\n",
        "    \"\"\"\n",
        "    raise RuntimeError(supported_freq_msg)\n",
        "\n",
        "\n",
        "def time_features(dates, freq='h'):\n",
        "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])\n"
      ],
      "metadata": {
        "id": "HiHQBWT-TMQ2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 tools"
      ],
      "metadata": {
        "id": "fXWOL3TaKzz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
        "    if args.lradj == 'type1':\n",
        "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
        "    elif args.lradj == 'type2':\n",
        "        lr_adjust = {\n",
        "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
        "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
        "        }\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print('Updating learning rate to {}'.format(lr))\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "class StandardScaler():\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def transform(self, data):\n",
        "        return (data - self.mean) / self.std\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return (data * self.std) + self.mean\n",
        "\n",
        "\n",
        "def visual(true, preds=None, name='./pic/test.pdf'):\n",
        "    \"\"\"\n",
        "    Results visualization\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(true, label='GroundTruth', linewidth=2)\n",
        "    if preds is not None:\n",
        "        plt.plot(preds, label='Prediction', linewidth=2)\n",
        "    plt.legend()\n",
        "    plt.savefig(name, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "Fm6C7KYLTXIi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.layers"
      ],
      "metadata": {
        "id": "7_lNv2HPb4BM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1AutoCorrelation"
      ],
      "metadata": {
        "id": "yLSM7Z0pcCej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "import os\n",
        "\n",
        "\n",
        "class AutoCorrelation(nn.Module):\n",
        "    \"\"\"\n",
        "    AutoCorrelation Mechanism with the following two phases:\n",
        "    (1) period-based dependencies discovery\n",
        "    (2) time delay aggregation\n",
        "    This block can replace the self-attention family mechanism seamlessly.\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(AutoCorrelation, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def time_delay_agg_training(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the training phase.\n",
        "        \"\"\"\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
        "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_inference(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the inference phase.\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_full(self, values, corr):\n",
        "        \"\"\"\n",
        "        Standard version of Autocorrelation\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
        "        return delays_agg\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        if L > S:\n",
        "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
        "            values = torch.cat([values, zeros], dim=1)\n",
        "            keys = torch.cat([keys, zeros], dim=1)\n",
        "        else:\n",
        "            values = values[:, :L, :, :]\n",
        "            keys = keys[:, :L, :, :]\n",
        "\n",
        "        # period-based dependencies\n",
        "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        res = q_fft * torch.conj(k_fft)\n",
        "        corr = torch.fft.irfft(res, dim=-1)\n",
        "\n",
        "        # time delay agg\n",
        "        if self.training:\n",
        "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "        else:\n",
        "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class AutoCorrelationLayer(nn.Module):\n",
        "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AutoCorrelationLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_correlation = correlation\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_correlation(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n"
      ],
      "metadata": {
        "id": "WqK3xTtab55F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2Autoformer encoder decoder"
      ],
      "metadata": {
        "id": "84o3uGkScJjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class my_Layernorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Special designed layernorm for the seasonal part\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(my_Layernorm, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_hat = self.layernorm(x)\n",
        "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
        "        return x_hat - bias\n",
        "\n",
        "\n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        x, _ = self.decomp1(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        res, _ = self.decomp2(x + y)\n",
        "        return res, attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer decoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
        "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.decomp3 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
        "                                    padding_mode='circular', bias=False)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x, trend1 = self.decomp1(x)\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "        x, trend2 = self.decomp2(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        x, trend3 = self.decomp3(x + y)\n",
        "\n",
        "        residual_trend = trend1 + trend2 + trend3\n",
        "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x, residual_trend\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
        "        for layer in self.layers:\n",
        "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "            trend = trend + residual_trend\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x, trend\n"
      ],
      "metadata": {
        "id": "Agyvwx9hcMwU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3Embedding"
      ],
      "metadata": {
        "id": "eJ4TcAmNcbvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        # u = torch.tensor(300.) # 100<u<500                                 # **************************\n",
        "        # self.u_law_function = lambda w: (torch.log(torch.tensor(1.)+torch.abs(w)*u ))/(torch.log(torch.tensor(1.)+u))    #***************************\n",
        "\n",
        "        self.iter_embedding_matrix_show = 0\n",
        "    def forward(self, x):\n",
        "        # x = self.u_law_function(x)                              #***************************\n",
        "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
        "        self.iter_embedding_matrix_show = self.iter_embedding_matrix_show +1\n",
        "        joblib.dump(x, '/content/drive/MyDrive/DATA_reformer/iter_embedding_matrix_show/x_{}.pkl'.format(self.iter_embedding_matrix_show)) \n",
        "        return x\n",
        "\n",
        "\n",
        "class FixedEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(FixedEmbedding, self).__init__()\n",
        "\n",
        "        w = torch.zeros(c_in, d_model).float()\n",
        "        w.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        w[:, 0::2] = torch.sin(position * div_term)\n",
        "        w[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.emb = nn.Embedding(c_in, d_model)\n",
        "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x).detach()\n",
        "\n",
        "\n",
        "class TemporalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
        "        super(TemporalEmbedding, self).__init__()\n",
        "\n",
        "        minute_size = 4\n",
        "        hour_size = 24\n",
        "        weekday_size = 7\n",
        "        day_size = 32\n",
        "        month_size = 13\n",
        "\n",
        "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
        "        if freq == 't':\n",
        "            self.minute_embed = Embed(minute_size, d_model)\n",
        "        self.hour_embed = Embed(hour_size, d_model)\n",
        "        self.weekday_embed = Embed(weekday_size, d_model)\n",
        "        self.day_embed = Embed(day_size, d_model)\n",
        "        self.month_embed = Embed(month_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "\n",
        "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
        "        hour_x = self.hour_embed(x[:, :, 3])\n",
        "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
        "        day_x = self.day_embed(x[:, :, 1])\n",
        "        month_x = self.month_embed(x[:, :, 0])\n",
        "\n",
        "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
        "\n",
        "\n",
        "class TimeFeatureEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
        "        super(TimeFeatureEmbedding, self).__init__()\n",
        "\n",
        "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
        "        d_inp = freq_map[freq]\n",
        "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "\n",
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class DataEmbedding_wo_pos(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding_wo_pos, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "O2GtrfuncaXT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4SelfAttention_Family"
      ],
      "metadata": {
        "id": "xMx3dGK_oAJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "from reformer_pytorch import LSHSelfAttention\n",
        "import os\n",
        "\n",
        "\n",
        "class FullAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(FullAttention, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        scale = self.scale or 1. / sqrt(E)\n",
        "\n",
        "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)   #按照爱因斯坦求和约定，当一个单独项目内有标号变量出现两次，一次是上标，一次是下标时，则必须总和所有这单独项目的可能值。\n",
        "\n",
        "        if self.mask_flag:\n",
        "            if attn_mask is None:\n",
        "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
        "\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
        "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), A)\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class ProbAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(ProbAttention, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def _prob_QK(self, Q, K, sample_k, n_top):  # n_top: c*ln(L_q)\n",
        "        # Q [B, H, L, D]\n",
        "        B, H, L_K, E = K.shape\n",
        "        _, _, L_Q, _ = Q.shape\n",
        "\n",
        "        # calculate the sampled Q_K\n",
        "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
        "        index_sample = torch.randint(L_K, (L_Q, sample_k))  # real U = U_part(factor*ln(L_k))*L_q\n",
        "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
        "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
        "\n",
        "        # find the Top_k query with sparisty measurement\n",
        "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
        "        M_top = M.topk(n_top, sorted=False)[1]\n",
        "\n",
        "        # use the reduced Q to calculate Q_K\n",
        "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
        "                   torch.arange(H)[None, :, None],\n",
        "                   M_top, :]  # factor*ln(L_q)\n",
        "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))  # factor*ln(L_q)*L_k\n",
        "\n",
        "        return Q_K, M_top\n",
        "\n",
        "    def _get_initial_context(self, V, L_Q):\n",
        "        B, H, L_V, D = V.shape\n",
        "        if not self.mask_flag:\n",
        "            # V_sum = V.sum(dim=-2)\n",
        "            V_sum = V.mean(dim=-2)\n",
        "            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n",
        "        else:  # use mask\n",
        "            assert (L_Q == L_V)  # requires that L_Q == L_V, i.e. for self-attention only\n",
        "            contex = V.cumsum(dim=-2)\n",
        "        return contex\n",
        "\n",
        "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
        "        B, H, L_V, D = V.shape\n",
        "\n",
        "        if self.mask_flag:\n",
        "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  # nn.Softmax(dim=-1)(scores)\n",
        "\n",
        "        context_in[torch.arange(B)[:, None, None],\n",
        "        torch.arange(H)[None, :, None],\n",
        "        index, :] = torch.matmul(attn, V).type_as(context_in)\n",
        "        if self.output_attention:\n",
        "            attns = (torch.ones([B, H, L_V, L_V]) / L_V).type_as(attn).to(attn.device)\n",
        "            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n",
        "            return (context_in, attns)\n",
        "        else:\n",
        "            return (context_in, None)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L_Q, H, D = queries.shape\n",
        "        _, L_K, _, _ = keys.shape\n",
        "\n",
        "        queries = queries.transpose(2, 1)\n",
        "        keys = keys.transpose(2, 1)\n",
        "        values = values.transpose(2, 1)\n",
        "\n",
        "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item()  # c*ln(L_k)\n",
        "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item()  # c*ln(L_q)\n",
        "\n",
        "        U_part = U_part if U_part < L_K else L_K\n",
        "        u = u if u < L_Q else L_Q\n",
        "\n",
        "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
        "\n",
        "        # add scale factor\n",
        "        scale = self.scale or 1. / sqrt(D)\n",
        "        if scale is not None:\n",
        "            scores_top = scores_top * scale\n",
        "        # get the context\n",
        "        context = self._get_initial_context(values, L_Q)\n",
        "        # update the context with selected top_k queries\n",
        "        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n",
        "\n",
        "        return context.contiguous(), attn\n",
        "\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_attention = attention\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_attention(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n",
        "\n",
        "\n",
        "class ReformerLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
        "        super().__init__()\n",
        "        self.bucket_size = bucket_size\n",
        "        self.attn = LSHSelfAttention(\n",
        "            dim=d_model,\n",
        "            heads=n_heads,\n",
        "            bucket_size=bucket_size,\n",
        "            n_hashes=n_hashes,\n",
        "            causal=causal\n",
        "        )\n",
        "\n",
        "    def fit_length(self, queries):\n",
        "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
        "        B, N, C = queries.shape\n",
        "        if N % (self.bucket_size * 2) == 0:\n",
        "            return queries\n",
        "        else:\n",
        "            # fill the time series\n",
        "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
        "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        # in Reformer: defalut queries=keys\n",
        "        B, N, C = queries.shape\n",
        "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
        "        return queries, None\n"
      ],
      "metadata": {
        "id": "lIt9j_ZHoVKe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5Transformer_EncDec"
      ],
      "metadata": {
        "id": "WTKTm3kIolKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
        "                                  out_channels=c_in,\n",
        "                                  kernel_size=3,\n",
        "                                  padding=2,\n",
        "                                  padding_mode='circular')\n",
        "        self.norm = nn.BatchNorm1d(c_in)\n",
        "        self.activation = nn.ELU()\n",
        "        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downConv(x.permute(0, 2, 1))\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxPool(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm2(x + y), attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        # x [B, L, D]\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
        "                 dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "\n",
        "        y = x = self.norm2(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm3(x + y)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "qU3EDdg-ongG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.data provider"
      ],
      "metadata": {
        "id": "Lm0TRcMPSr9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 data_loader"
      ],
      "metadata": {
        "id": "BgImJJEOW5fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from utils.timefeatures import time_features\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        print(df_raw)\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * 0.7)\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "    \n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "            cols.remove(self.target)\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            cols.remove(self.target)\n",
        "            cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n"
      ],
      "metadata": {
        "id": "cdfMzEkNSwzU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2data_factory"
      ],
      "metadata": {
        "id": "zITfhuNwWve4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_dict = {\n",
        "    'ETTh1': Dataset_ETT_hour,\n",
        "    'ETTh2': Dataset_ETT_hour,\n",
        "    'ETTm1': Dataset_ETT_minute,\n",
        "    'ETTm2': Dataset_ETT_minute,\n",
        "    'custom': Dataset_Custom,\n",
        "}\n",
        "\n",
        "\n",
        "def data_provider(args, flag):\n",
        "    Data = data_dict[args.data]\n",
        "    timeenc = 0 if args.embed != 'timeF' else 1\n",
        "    print(Data)\n",
        "    print(timeenc)\n",
        "    if flag == 'test':\n",
        "        shuffle_flag = False\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "    elif flag == 'pred':\n",
        "        shuffle_flag = False\n",
        "        drop_last = False\n",
        "        batch_size = 1\n",
        "        freq = args.freq\n",
        "        Data = Dataset_Pred\n",
        "    else:\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "\n",
        "    data_set = Data(\n",
        "        root_path=args.root_path,\n",
        "        data_path=args.data_path,\n",
        "        flag=flag,\n",
        "        size=[args.seq_len, args.label_len, args.pred_len],\n",
        "        features=args.features,\n",
        "        target=args.target,\n",
        "        timeenc=timeenc,\n",
        "        freq=freq\n",
        "    )\n",
        "    print(flag, len(data_set))\n",
        "    data_loader = DataLoader(\n",
        "        data_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_flag,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=drop_last)\n",
        "    return data_set, data_loader\n"
      ],
      "metadata": {
        "id": "IWZeKnfeUUn7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = Dataset_ETT_hour(\n",
        "        root_path='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/',\n",
        "        data_path='REFINED_NBC news G16B3-QP28.csv',\n",
        "        flag='test',\n",
        "        size=[98, 48, 24],\n",
        "        features='M',\n",
        "        target='OT',\n",
        "        timeenc=1,\n",
        "        # freq='d'\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "xpHbE97AJFMv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 0\n",
        "# for item in data_set:\n",
        "#   if i < 1:\n",
        "#     i = i + 1\n",
        "#     print(item)"
      ],
      "metadata": {
        "id": "c5AAmQxXN9JJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_provider.timeenc"
      ],
      "metadata": {
        "id": "FhuwQ28lJKTo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args.data\n",
        "# args.freq\n",
        "# args.target,\n",
        "# args.features"
      ],
      "metadata": {
        "id": "xN2VPTltANAc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# args.root_path,"
      ],
      "metadata": {
        "id": "ggqTaWtqBZpE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '''data_set'''\n",
        "# i = 0\n",
        "# print(\"data_set:\", data_set)\n",
        "# for item in data_loader:\n",
        "#   i = i+1\n",
        "#   if i < 5:\n",
        "#     print(\"item:\", item)\n",
        "#     print(\"item size:\", len(item))"
      ],
      "metadata": {
        "id": "SMhEdQ1__8a8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.model"
      ],
      "metadata": {
        "id": "rn4mhqeGWGbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.0.transformer"
      ],
      "metadata": {
        "id": "XEQKNrGVV1nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Embed import DataEmbedding, DataEmbedding_wo_pos\n",
        "# from layers.AutoCorrelation import AutoCorrelation, AutoCorrelationLayer\n",
        "# from layers.Autoformer_EncDec import Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer is the first method to achieve the series-wise connection,\n",
        "    with inherent O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_transformer, self).__init__()\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.label_len = configs.label_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Decomp\n",
        "        kernel_size = configs.moving_avg\n",
        "        self.decomp = series_decomp(kernel_size)\n",
        "\n",
        "        # Embedding\n",
        "        # The series-wise connection inherently contains the sequential information.\n",
        "        # Thus, we can discard the position embedding of transformers.\n",
        "        self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding_wo_pos(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(True, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.c_out,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # decomp init\n",
        "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
        "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device)\n",
        "        seasonal_init, trend_init = self.decomp(x_enc)\n",
        "        # decoder input\n",
        "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
        "        seasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n",
        "        # enc\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        # dec\n",
        "        dec_out = self.dec_embedding(seasonal_init, x_mark_dec)\n",
        "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
        "                                                 trend=trend_init)\n",
        "        # final\n",
        "        dec_out = trend_part + seasonal_part\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "3aIRCR44bstE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1.autoformer"
      ],
      "metadata": {
        "id": "lh-wb_oDcZq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_autoformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Vanilla Transformer with O(L^2) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_autoformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "UzH_MdaLV6fo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 informer"
      ],
      "metadata": {
        "id": "pO1t1HZNfST2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, ProbAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_informer(nn.Module):\n",
        "    \"\"\"\n",
        "    Informer with Propspare attention in O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_informer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            [\n",
        "                ConvLayer(\n",
        "                    configs.d_model\n",
        "                ) for l in range(configs.e_layers - 1)\n",
        "            ] if configs.distil else None,\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "d8hMhyLGfUJO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 reformer"
      ],
      "metadata": {
        "id": "phxv-52XfZxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import ReformerLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_reformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Reformer with O(LlogL) complexity\n",
        "    - It is notable that Reformer is not proposed for time series forecasting, in that it cannot accomplish the cross attention.\n",
        "    - Here is only one adaption in BERT-style, other possible implementations can also be acceptable.\n",
        "    - The hyper-parameters, such as bucket_size and n_hashes, need to be further tuned.\n",
        "    The official repo of Reformer (https://github.com/lucidrains/reformer-pytorch) can be very helpful, if you have any questiones.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super(Model_reformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    ReformerLayer(None, configs.d_model, configs.n_heads, bucket_size=configs.bucket_size,\n",
        "                                  n_hashes=configs.n_hashes),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        self.projection = nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # add placeholder\n",
        "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        x_mark_enc = torch.cat([x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        # Reformer: encoder only\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        enc_out = self.projection(enc_out)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return enc_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return enc_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ],
      "metadata": {
        "id": "OWuGfTFWfhMQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.exp"
      ],
      "metadata": {
        "id": "eyAd4Xzgdn7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 exp_basic"
      ],
      "metadata": {
        "id": "vZnDaWqEd1cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Exp_Basic(object):\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.device = self._acquire_device()\n",
        "        self.model = self._build_model().to(self.device)\n",
        "\n",
        "    def _build_model(self):\n",
        "        raise NotImplementedError\n",
        "        return None\n",
        "\n",
        "    def _acquire_device(self):\n",
        "        if self.args.use_gpu:\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
        "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
        "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
        "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "            print('Use CPU')\n",
        "        return device\n",
        "\n",
        "    def _get_data(self):\n",
        "        pass\n",
        "\n",
        "    def vali(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def test(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "_kDMmjLddsCC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 exp_main"
      ],
      "metadata": {
        "id": "eaqW13S4fAXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from data_provider.data_factory import data_provider\n",
        "# from exp.exp_basic import Exp_Basic\n",
        "# from models import Informer, Autoformer, Transformer, Reformer\n",
        "# from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
        "# from utils.metrics import metric\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Exp_Main(Exp_Basic):\n",
        "    def __init__(self, args):\n",
        "        super(Exp_Main, self).__init__(args)\n",
        "\n",
        "    def _build_model(self):\n",
        "        model_dict = {\n",
        "            'Autoformer': Model_autoformer,\n",
        "            'Transformer': Model_transformer,\n",
        "            'Informer': Model_informer,\n",
        "            'Reformer': Model_reformer,\n",
        "        }\n",
        "        # model_dict = {\n",
        "        #     'Autoformer': Autoformer,\n",
        "        #     'Transformer': Transformer,\n",
        "        #     'Informer': Informer,\n",
        "        #     'Reformer': Reformer,\n",
        "        # }\n",
        "        # model = model_dict[self.args.model].Model(self.args).float()\n",
        "        model = model_dict[self.args.model](self.args).float()\n",
        "\n",
        "\n",
        "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
        "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
        "        return model\n",
        "\n",
        "    def _get_data(self, flag):\n",
        "        data_set, data_loader = data_provider(self.args, flag)\n",
        "        return data_set, data_loader\n",
        "\n",
        "    def _select_optimizer(self):\n",
        "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _select_criterion(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def vali(self, vali_data, vali_loader, criterion):\n",
        "        total_loss = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "\n",
        "                pred = outputs.detach().cpu()\n",
        "                true = batch_y.detach().cpu()\n",
        "\n",
        "                loss = criterion(pred, true)\n",
        "\n",
        "                total_loss.append(loss)\n",
        "        total_loss = np.average(total_loss)\n",
        "        self.model.train()\n",
        "        return total_loss\n",
        "\n",
        "    def train(self, setting):\n",
        "        train_data, train_loader = self._get_data(flag='train')\n",
        "        vali_data, vali_loader = self._get_data(flag='val')\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        path = os.path.join(self.args.checkpoints, setting)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        time_now = time.time()\n",
        "\n",
        "        train_steps = len(train_loader)\n",
        "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
        "\n",
        "        model_optim = self._select_optimizer()\n",
        "        criterion = self._select_criterion()\n",
        "\n",
        "        if self.args.use_amp:\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        for epoch in range(self.args.train_epochs):\n",
        "            iter_count = 0\n",
        "            train_loss = []\n",
        "\n",
        "            self.model.train()\n",
        "            epoch_time = time.time()\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "                iter_count += 1\n",
        "                model_optim.zero_grad()\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                        loss = criterion(outputs, batch_y)\n",
        "                        train_loss.append(loss.item())\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
        "\n",
        "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    train_loss.append(loss.item())\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                if self.args.use_amp:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(model_optim)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    model_optim.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            train_loss = np.average(train_loss)\n",
        "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
        "            test_loss = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
        "            early_stopping(vali_loss, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
        "\n",
        "        best_model_path = path + '/' + 'checkpoint.pth'\n",
        "        self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def test(self, setting, test=0):\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "        if test:\n",
        "            print('loading model')\n",
        "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        folder_path = './test_results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                outputs = outputs.detach().cpu().numpy()\n",
        "                batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "                if i % 20 == 0:\n",
        "                    input = batch_x.detach().cpu().numpy()\n",
        "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
        "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
        "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        trues = np.array(trues)\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
        "        print('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f = open(\"result.txt\", 'a')\n",
        "        f.write(setting + \"  \\n\")\n",
        "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f.write('\\n')\n",
        "        f.write('\\n')\n",
        "        f.close()\n",
        "\n",
        "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
        "        np.save(folder_path + 'pred.npy', preds)\n",
        "        np.save(folder_path + 'true.npy', trues)\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, setting, load=False):\n",
        "        pred_data, pred_loader = self._get_data(flag='pred')\n",
        "\n",
        "        if load:\n",
        "            path = os.path.join(self.args.checkpoints, setting)\n",
        "            best_model_path = path + '/' + 'checkpoint.pth'\n",
        "            self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                preds.append(pred)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        np.save(folder_path + 'real_prediction.npy', preds)\n",
        "\n",
        "        return preds"
      ],
      "metadata": {
        "id": "hoDRz8yifA2I"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict"
      ],
      "metadata": {
        "id": "MUdH5LufYdg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n"
      ],
      "metadata": {
        "id": "jb1pRBEDYiqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475fff39-9259-4ea2-9cbe-5f8449a5c69f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available() \n",
        "import torch\n",
        "torch.cuda.set_device(0)"
      ],
      "metadata": {
        "id": "yYISGR-rbc2_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "# from exp.exp_main import Exp_Main#exp stands for experiments\n",
        "import random\n",
        "import numpy as np\n",
        "# from utils.tools import dotdict\n",
        "\n",
        "fix_seed = 2021 \n",
        "random.seed(fix_seed)\n",
        "torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')#模型id\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',#选择模型\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')#数据类型\n",
        "parser.add_argument('--root_path', type=str, default='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', help='root path of the data file')#数据文件夹路径\n",
        "parser.add_argument('--data_path', type=str, default='ETTh1.csv', help='data file')#具体文件\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')#预测类别\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')#不太懂 OT好像代表Output Target,要预测的单变量\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='/content/drive/MyDrive/DATA_reformer/checkpoints/', help='location of model checkpoints')#保存模型\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')#输入序列长度\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')#这个label_len未完全搞懂\n",
        "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')#输出序列长度\n",
        "\n",
        "# model define\n",
        "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')#encoder input size\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')#decoder input size\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')#输出长度\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')#dimension of model\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')#num of heads \n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')#num of encoder layers\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')#num of decoder layers\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')#dimension of fcn\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')#窗口滑动平均数\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')#attn factor不太理解\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)#是否在encoder里面使用知识蒸馏\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')#dropout\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')#time features encoding不太能get到\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')#激活函数default=gelu\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')#encoder的output_attention是否输出\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')#是否预测未见的未来数据,也就是是否进行推理的意思\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')# num_workers是加载数据(batch)的线程数目\n",
        "parser.add_argument('--itr', type=int, default=2, help='experiments times')#实验次数\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')#就是epoch\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')#bathsize\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')#patience: 当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')#lr\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')#test\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')#loss is mse\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')#adjust learning-rate\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)#使用自动混合精度训练\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args = dotdict()\n",
        "args.target = 'OT'\n",
        "args.des = 'test'\n",
        "args.dropout = 0.05\n",
        "args.num_workers = 10\n",
        "args.gpu = 0\n",
        "args.lradj = 'type1'\n",
        "args.devices = '0'\n",
        "args.use_gpu = True\n",
        "args.use_multi_gpu = False\n",
        "# if args.use_gpu and args.use_multi_gpu: #是否使用多卡的判断\n",
        "#     args.dvices = args.devices.replace(' ', '')\n",
        "#     device_ids = args.devices.split(',')\n",
        "#     args.device_ids = [int(id_) for id_ in device_ids]\n",
        "#     args.gpu = args.device_ids[0]\n",
        "args.freq = 'h'\n",
        "args.checkpoints = '/content/drive/MyDrive/DATA_reformer/checkpoints/'\n",
        "args.bucket_size = 4\n",
        "args.n_hashes = 4\n",
        "args.is_trainging = True\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path ='REFINED_NBC news G16B3-QP28.csv' \n",
        "args.model_id='ETTh1_96_24'\n",
        "args.model = 'Autoformer'\n",
        "args.data = 'ETTh1'\n",
        "args.features = 'M'\n",
        "args.seq_len = 96\n",
        "args.label_len = 48\n",
        "args.pred_len = 24\n",
        "args.e_layers = 2\n",
        "args.d_layers = 1\n",
        "args.n_heads = 8\n",
        "args.factor = 1\n",
        "args.enc_in = 7\n",
        "args.dec_in =7\n",
        "args.c_out = 7\n",
        "args.d_model = 512\n",
        "\n",
        "args.des = 'Exp'\n",
        "args.itr = 1      #1\n",
        "args.d_ff = 2048\n",
        "args.moving_avg = 25\n",
        "args.factor = 1\n",
        "args.distil = True\n",
        "args.output_attention = False\n",
        "args.patience= 3\n",
        "args.learning_rate = 0.0001\n",
        "args.batch_size = 32 \n",
        "args.embed = 'timeF'\n",
        "args.activation = 'gelu'\n",
        "args.use_amp = False\n",
        "args.loss = 'mse'\n",
        "args.train_epochs = 10    #10\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "# Exp = Exp_Main\n",
        "\n"
      ],
      "metadata": {
        "id": "S3PkcjfqbkHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee49a394-9121-4ac5-f50d-d8548de5c8c0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 10, 'gpu': 0, 'lradj': 'type1', 'devices': '0', 'use_gpu': True, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': '/content/drive/MyDrive/DATA_reformer/checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', 'data_path': 'REFINED_NBC news G16B3-QP28.csv', 'model_id': 'ETTh1_96_24', 'model': 'Autoformer', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "for ii in range(args.itr):#itr就是实验次数可不是epoch，parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "        args.model_id,\n",
        "        args.model,\n",
        "        args.data,\n",
        "        args.features,\n",
        "        args.seq_len,\n",
        "        args.label_len,\n",
        "        args.pred_len,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        args.d_layers,\n",
        "        args.d_ff,\n",
        "        args.factor,\n",
        "        args.embed,\n",
        "        args.distil,\n",
        "        args.des, ii)\n",
        "\n",
        "    exp = Exp_Main(args)  # set experiments\n",
        "    print(1)\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)#setting是用来保存模型的名字用的，很细节\n",
        "    print(2)\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(3)\n",
        "\n"
      ],
      "metadata": {
        "id": "gkA3f_QHeIlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c17f054-ee98-4a0c-fdc6-8a8face7a930"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU: cuda:0\n",
            "1\n",
            ">>>>>>>start training : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "train 8521\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "val 2857\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "test 2857\n",
            "\titers: 100, epoch: 1 | loss: 0.5696512\n",
            "\tspeed: 0.1124s/iter; left time: 287.8532s\n",
            "\titers: 200, epoch: 1 | loss: 0.5108873\n",
            "\tspeed: 0.1082s/iter; left time: 266.2295s\n",
            "Epoch: 1 cost time: 29.09439992904663\n",
            "Epoch: 1, Steps: 266 | Train Loss: 0.5592872 Vali Loss: 0.6485763 Test Loss: 0.7742596\n",
            "Validation loss decreased (inf --> 0.648576).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.5084623\n",
            "\tspeed: 0.2988s/iter; left time: 685.8213s\n",
            "\titers: 200, epoch: 2 | loss: 0.4206936\n",
            "\tspeed: 0.1017s/iter; left time: 223.1550s\n",
            "Epoch: 2 cost time: 27.76947021484375\n",
            "Epoch: 2, Steps: 266 | Train Loss: 0.4541259 Vali Loss: 0.5521846 Test Loss: 0.6264822\n",
            "Validation loss decreased (0.648576 --> 0.552185).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.4735519\n",
            "\tspeed: 0.2996s/iter; left time: 607.9247s\n",
            "\titers: 200, epoch: 3 | loss: 0.3486905\n",
            "\tspeed: 0.1034s/iter; left time: 199.5228s\n",
            "Epoch: 3 cost time: 28.07761025428772\n",
            "Epoch: 3, Steps: 266 | Train Loss: 0.3461906 Vali Loss: 0.5499093 Test Loss: 0.6715450\n",
            "Validation loss decreased (0.552185 --> 0.549909).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.2647196\n",
            "\tspeed: 0.3005s/iter; left time: 529.8256s\n",
            "\titers: 200, epoch: 4 | loss: 0.3353718\n",
            "\tspeed: 0.1043s/iter; left time: 173.4673s\n",
            "Epoch: 4 cost time: 28.358322381973267\n",
            "Epoch: 4, Steps: 266 | Train Loss: 0.3044721 Vali Loss: 0.6010799 Test Loss: 0.7238552\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.2482807\n",
            "\tspeed: 0.2967s/iter; left time: 444.1631s\n",
            "\titers: 200, epoch: 5 | loss: 0.2516367\n",
            "\tspeed: 0.1040s/iter; left time: 145.3278s\n",
            "Epoch: 5 cost time: 27.898521184921265\n",
            "Epoch: 5, Steps: 266 | Train Loss: 0.2840302 Vali Loss: 0.5739439 Test Loss: 0.7017089\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.2142778\n",
            "\tspeed: 0.2967s/iter; left time: 365.2289s\n",
            "\titers: 200, epoch: 6 | loss: 0.2430922\n",
            "\tspeed: 0.1032s/iter; left time: 116.7355s\n",
            "Epoch: 6 cost time: 27.811447381973267\n",
            "Epoch: 6, Steps: 266 | Train Loss: 0.2727422 Vali Loss: 0.5712124 Test Loss: 0.7082267\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            "2\n",
            ">>>>>>>testing : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "test 2857\n",
            "test shape: (89, 32, 24, 7) (89, 32, 24, 7)\n",
            "test shape: (2848, 24, 7) (2848, 24, 7)\n",
            "mse:0.6715450882911682, mae:0.6721919775009155\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plot"
      ],
      "metadata": {
        "id": "JzsdzOBEZmhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom data: xxx.csv\n",
        "# data features: ['date', ...(other features), target feature]\n",
        "\n",
        "# we take ETTh2 as an example #模仿informer 的 colab example的custom_dataset与predict部分\n",
        "import pandas as pd\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path = 'ETTh2.csv'\n",
        "\n",
        "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
      ],
      "metadata": {
        "id": "ITsBvf3CZrKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.do_predict = True\n",
        "if args.do_predict:\n",
        "    print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    prediction=exp.predict(setting, True)#data_factory做好了pred里面的batch_size=1的情况，是autoformer在informer基础之上做的\n",
        "    torch.cuda.empty_cache()\n",
        "    print('>>>end>>>>')"
      ],
      "metadata": {
        "id": "c0NgpX76cK2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setting"
      ],
      "metadata": {
        "id": "t8Kr9FozffdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "5_jTxIgOclvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "#预测OT\n",
        "plt.plot(prediction[-1,:,-1])#由于prediction.shape是[1,24,7]那么batch只有1 索引只能是0或-1 都是代表batch这一维本身\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "plt.plot(prediction[0,:,-1])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "# draw HUFL prediction\n",
        "plt.plot(prediction[0,:,0])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UyQ5MQyGcYWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# try"
      ],
      "metadata": {
        "id": "veiY5xDj5nYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp.train(setting)"
      ],
      "metadata": {
        "id": "_6YDJ0TC4nyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path=args.root_path\n",
        "data_path=args.data_path\n",
        "print(\"root_path:\", root_path)\n",
        "print(\"data_path:\", data_path)\n",
        "print(\"[args.seq_len, args.label_len, args.pred_len]:\", [args.seq_len, args.label_len, args.pred_len])\n",
        "print(\"args.features:\", args.features)\n",
        "print(\"args.target:\", args.target)\n",
        "print(\"args.freq:\", args.freq)\n",
        "\n",
        "data_set, data_loader = data_provider(args, flag='test')"
      ],
      "metadata": {
        "id": "snWDvZfm5gaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set\n",
        "i = 0\n",
        "print(\"data_set:\", data_set)\n",
        "for item in data_loader:\n",
        "  i = i+1\n",
        "  if i < 5:\n",
        "    print(\"item:\", item)\n",
        "    print(\"item size:\", len(item))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KmJCZCAI64eS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}