{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/breakwa/xxxformer/blob/main/xxxformer%E9%A1%B9%E7%9B%AE_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vubyce0ywMHD"
      },
      "source": [
        "# requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADN5_hBilzlQ",
        "outputId": "48a0f03f-352e-47eb-beaf-728916518139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvlo2FAMv3qL",
        "outputId": "3f7c6bcd-b2aa-47ff-e1ae-cb25c4efb54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: reformer_pytorch in /usr/local/lib/python3.7/dist-packages (1.4.4)\n",
            "Requirement already satisfied: local-attention in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.4.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.5.0)\n",
            "Requirement already satisfied: axial-positional-embedding>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.2.1)\n",
            "Requirement already satisfied: product-key-memory in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (0.1.10)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from reformer_pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->reformer_pytorch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install reformer_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XdEzMXelt5GN"
      },
      "outputs": [],
      "source": [
        "import reformer_pytorch\n",
        "import pandas\n",
        "import sklearn\n",
        "import torchvision\n",
        "import numpy\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igxTD7r-wPoN",
        "outputId": "613d138c-7876-43db-e01b-e6dc755f459d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n",
        "import os\n",
        "os.system('CUDA_LAUNCH_BLOCKING=1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ9i2_q8TI9b"
      },
      "source": [
        "# 3.utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXLUb5ZaKldQ"
      },
      "source": [
        "## 3.1 download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Uk-umGQnTuGx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    source_url = 'https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/files/?p=%2Fall_six_datasets.zip&dl=1'\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    res = requests.get(source_url, headers=headers)\n",
        "\n",
        "    with open('/content/drive/MyDrive/DATA_reformer/datasets.zip', 'wb') as f:\n",
        "        f.write(res.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3cRa1YKpV0"
      },
      "source": [
        "## 3.2 mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "obcQnGROTkA5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class TriangularCausalMask():\n",
        "    def __init__(self, B, L, device=\"cpu\"):\n",
        "        mask_shape = [B, 1, L, L]\n",
        "        with torch.no_grad():\n",
        "            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n",
        "\n",
        "\n",
        "class ProbMask():\n",
        "    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n",
        "        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n",
        "        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n",
        "        indicator = _mask_ex[torch.arange(B)[:, None, None],\n",
        "                    torch.arange(H)[None, :, None],\n",
        "                    index, :].to(device)\n",
        "        self._mask = indicator.view(scores.shape).to(device)\n",
        "\n",
        "    @property\n",
        "    def mask(self):\n",
        "        return self._mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPSXrQVJKrbI"
      },
      "source": [
        "## 3.3 metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2XbBa4abTZV0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def RSE(pred, true):\n",
        "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
        "\n",
        "\n",
        "def CORR(pred, true):\n",
        "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)  #.sum(0) axis=0       .mean(0) axis=0 \n",
        "    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n",
        "    return (u / d).mean(-1)\n",
        "\n",
        "\n",
        "def MAE(pred, true):\n",
        "    return np.mean(np.abs(pred - true))\n",
        "\n",
        "\n",
        "def MSE(pred, true):\n",
        "    return np.mean((pred - true) ** 2)\n",
        "\n",
        "\n",
        "def RMSE(pred, true):\n",
        "    return np.sqrt(MSE(pred, true))\n",
        "\n",
        "\n",
        "def MAPE(pred, true):\n",
        "    return np.mean(np.abs((pred - true) / true))\n",
        "\n",
        "\n",
        "def MSPE(pred, true):\n",
        "    return np.mean(np.square((pred - true) / true))\n",
        "\n",
        "\n",
        "def metric(pred, true):\n",
        "    mae = MAE(pred, true)\n",
        "    mse = MSE(pred, true)\n",
        "    rmse = RMSE(pred, true)\n",
        "    mape = MAPE(pred, true)\n",
        "    mspe = MSPE(pred, true)\n",
        "\n",
        "    return mae, mse, rmse, mape, mspe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lyx0uUtKvTB"
      },
      "source": [
        "## 3.4 time features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HiHQBWT-TMQ2"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.tseries import offsets\n",
        "from pandas.tseries.frequencies import to_offset\n",
        "\n",
        "\n",
        "class TimeFeature:   #将dataframe转换为ndarry\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \"()\"\n",
        "\n",
        "\n",
        "class SecondOfMinute(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.second / 59.0 - 0.5         # 0-1    --->     (-0.5,0.5)\n",
        "\n",
        "\n",
        "class MinuteOfHour(TimeFeature):\n",
        "    \"\"\"Minute of hour encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.minute / 59.0 - 0.5\n",
        "\n",
        "\n",
        "class HourOfDay(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.hour / 23.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfWeek(TimeFeature):\n",
        "    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return index.dayofweek / 6.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfMonth(TimeFeature):\n",
        "    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.day - 1) / 30.0 - 0.5\n",
        "\n",
        "\n",
        "class DayOfYear(TimeFeature):\n",
        "    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.dayofyear - 1) / 365.0 - 0.5\n",
        "\n",
        "\n",
        "class MonthOfYear(TimeFeature):\n",
        "    \"\"\"Month of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.month - 1) / 11.0 - 0.5\n",
        "\n",
        "\n",
        "class WeekOfYear(TimeFeature):\n",
        "    \"\"\"Week of year encoded as value between [-0.5, 0.5]\"\"\"\n",
        "\n",
        "    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "        return (index.isocalendar().week - 1) / 52.0 - 0.5\n",
        "\n",
        "\n",
        "def time_features_from_frequency_str(freq_str: str) -> List[TimeFeature]:\n",
        "    \"\"\"\n",
        "    Returns a list of time features that will be appropriate for the given frequency string.\n",
        "    Parameters\n",
        "    ----------\n",
        "    freq_str\n",
        "        Frequency string of the form [multiple][granularity] such as \"12H\", \"5min\", \"1D\" etc.\n",
        "    \"\"\"\n",
        "\n",
        "    features_by_offsets = {\n",
        "        offsets.YearEnd: [],\n",
        "        offsets.QuarterEnd: [MonthOfYear],\n",
        "        offsets.MonthEnd: [MonthOfYear],\n",
        "        offsets.Week: [DayOfMonth, WeekOfYear],\n",
        "        offsets.Day: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.BusinessDay: [DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Hour: [HourOfDay, DayOfWeek, DayOfMonth, DayOfYear],\n",
        "        offsets.Minute: [\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "        offsets.Second: [\n",
        "            SecondOfMinute,\n",
        "            MinuteOfHour,\n",
        "            HourOfDay,\n",
        "            DayOfWeek,\n",
        "            DayOfMonth,\n",
        "            DayOfYear,\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    offset = to_offset(freq_str)\n",
        "\n",
        "    for offset_type, feature_classes in features_by_offsets.items():\n",
        "        if isinstance(offset, offset_type):\n",
        "            return [cls() for cls in feature_classes]\n",
        "\n",
        "    supported_freq_msg = f\"\"\"\n",
        "    Unsupported frequency {freq_str}\n",
        "    The following frequencies are supported:\n",
        "        Y   - yearly\n",
        "            alias: A\n",
        "        M   - monthly\n",
        "        W   - weekly\n",
        "        D   - daily\n",
        "        B   - business days\n",
        "        H   - hourly\n",
        "        T   - minutely\n",
        "            alias: min\n",
        "        S   - secondly\n",
        "    \"\"\"\n",
        "    raise RuntimeError(supported_freq_msg)\n",
        "\n",
        "\n",
        "def time_features(dates, freq='h'):\n",
        "    return np.vstack([feat(dates) for feat in time_features_from_frequency_str(freq)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWOL3TaKzz2"
      },
      "source": [
        "## 3.5 tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Fm6C7KYLTXIi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
        "    if args.lradj == 'type1':\n",
        "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}\n",
        "    elif args.lradj == 'type2':\n",
        "        lr_adjust = {\n",
        "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
        "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
        "        }\n",
        "    if epoch in lr_adjust.keys():\n",
        "        lr = lr_adjust[epoch]\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        print('Updating learning rate to {}'.format(lr))\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, path):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "class StandardScaler():\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def transform(self, data):\n",
        "        return (data - self.mean) / self.std\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return (data * self.std) + self.mean\n",
        "\n",
        "\n",
        "def visual(true, preds=None, name='./pic/test.pdf'):\n",
        "    \"\"\"\n",
        "    Results visualization\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(true, label='GroundTruth', linewidth=2)\n",
        "    if preds is not None:\n",
        "        plt.plot(preds, label='Prediction', linewidth=2)\n",
        "    plt.legend()\n",
        "    plt.savefig(name, bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_lNv2HPb4BM"
      },
      "source": [
        "# 1.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLSM7Z0pcCej"
      },
      "source": [
        "## 1.1AutoCorrelation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WqK3xTtab55F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "import os\n",
        "\n",
        "\n",
        "class AutoCorrelation(nn.Module):\n",
        "    \"\"\"\n",
        "    AutoCorrelation Mechanism with the following two phases:\n",
        "    (1) period-based dependencies discovery\n",
        "    (2) time delay aggregation\n",
        "    This block can replace the self-attention family mechanism seamlessly.\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_flag=True, factor=1, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(AutoCorrelation, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def time_delay_agg_training(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the training phase.\n",
        "        \"\"\"\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        index = torch.topk(torch.mean(mean_value, dim=0), top_k, dim=-1)[1]\n",
        "        weights = torch.stack([mean_value[:, index[i]] for i in range(top_k)], dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            pattern = torch.roll(tmp_values, -int(index[i]), -1)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_inference(self, values, corr):\n",
        "        \"\"\"\n",
        "        SpeedUp version of Autocorrelation (a batch-normalization style design)\n",
        "        This is for the inference phase.\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        mean_value = torch.mean(torch.mean(corr, dim=1), dim=1)\n",
        "        weights, delay = torch.topk(mean_value, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * \\\n",
        "                         (tmp_corr[:, i].unsqueeze(1).unsqueeze(1).unsqueeze(1).repeat(1, head, channel, length))\n",
        "        return delays_agg\n",
        "\n",
        "    def time_delay_agg_full(self, values, corr):\n",
        "        \"\"\"\n",
        "        Standard version of Autocorrelation\n",
        "        \"\"\"\n",
        "        batch = values.shape[0]\n",
        "        head = values.shape[1]\n",
        "        channel = values.shape[2]\n",
        "        length = values.shape[3]\n",
        "        # index init\n",
        "        init_index = torch.arange(length).unsqueeze(0).unsqueeze(0).unsqueeze(0)\\\n",
        "            .repeat(batch, head, channel, 1).to(values.device)\n",
        "        # find top k\n",
        "        top_k = int(self.factor * math.log(length))\n",
        "        weights, delay = torch.topk(corr, top_k, dim=-1)\n",
        "        # update corr\n",
        "        tmp_corr = torch.softmax(weights, dim=-1)\n",
        "        # aggregation\n",
        "        tmp_values = values.repeat(1, 1, 1, 2)\n",
        "        delays_agg = torch.zeros_like(values).float()\n",
        "        for i in range(top_k):\n",
        "            tmp_delay = init_index + delay[..., i].unsqueeze(-1)\n",
        "            pattern = torch.gather(tmp_values, dim=-1, index=tmp_delay)\n",
        "            delays_agg = delays_agg + pattern * (tmp_corr[..., i].unsqueeze(-1))\n",
        "        return delays_agg\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        if L > S:\n",
        "            zeros = torch.zeros_like(queries[:, :(L - S), :]).float()\n",
        "            values = torch.cat([values, zeros], dim=1)\n",
        "            keys = torch.cat([keys, zeros], dim=1)\n",
        "        else:\n",
        "            values = values[:, :L, :, :]\n",
        "            keys = keys[:, :L, :, :]\n",
        "\n",
        "        # period-based dependencies\n",
        "        q_fft = torch.fft.rfft(queries.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        k_fft = torch.fft.rfft(keys.permute(0, 2, 3, 1).contiguous(), dim=-1)\n",
        "        res = q_fft * torch.conj(k_fft)\n",
        "        corr = torch.fft.irfft(res, dim=-1)\n",
        "\n",
        "        # time delay agg\n",
        "        if self.training:\n",
        "            V = self.time_delay_agg_training(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "        else:\n",
        "            V = self.time_delay_agg_inference(values.permute(0, 2, 3, 1).contiguous(), corr).permute(0, 3, 1, 2)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), corr.permute(0, 3, 1, 2))\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class AutoCorrelationLayer(nn.Module):\n",
        "    def __init__(self, correlation, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AutoCorrelationLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_correlation = correlation\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_correlation(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84o3uGkScJjL"
      },
      "source": [
        "## 1.2Autoformer encoder decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Agyvwx9hcMwU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class my_Layernorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Special designed layernorm for the seasonal part\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(my_Layernorm, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_hat = self.layernorm(x)\n",
        "        bias = torch.mean(x_hat, dim=1).unsqueeze(1).repeat(1, x.shape[1], 1)\n",
        "        return x_hat - bias\n",
        "\n",
        "\n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, attention, d_model, d_ff=None, moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "        x, _ = self.decomp1(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        res, _ = self.decomp2(x + y)\n",
        "        return res, attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer decoder layer with the progressive decomposition architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, self_attention, cross_attention, d_model, c_out, d_ff=None,\n",
        "                 moving_avg=25, dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1, bias=False)\n",
        "        self.decomp1 = series_decomp(moving_avg)\n",
        "        self.decomp2 = series_decomp(moving_avg)\n",
        "        self.decomp3 = series_decomp(moving_avg)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.projection = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=3, stride=1, padding=1,\n",
        "                                    padding_mode='circular', bias=False)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x, trend1 = self.decomp1(x)\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "        x, trend2 = self.decomp2(x)\n",
        "        y = x\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "        x, trend3 = self.decomp3(x + y)\n",
        "\n",
        "        residual_trend = trend1 + trend2 + trend3\n",
        "        residual_trend = self.projection(residual_trend.permute(0, 2, 1)).transpose(1, 2)\n",
        "        return x, residual_trend\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None, trend=None):\n",
        "        for layer in self.layers:\n",
        "            x, residual_trend = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "            trend = trend + residual_trend\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x, trend\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ4TcAmNcbvj"
      },
      "source": [
        "## 1.3Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "O2GtrfuncaXT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model).float()\n",
        "        pe.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)]\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):                    #d_model = \n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
        "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
        "                                   kernel_size=3, padding=padding, padding_mode='circular', bias=False)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
        "        u = torch.tensor(d_model-1.) # 100<u<500                                 # **************************\n",
        "        self.u_law_function = lambda w: ((  torch.log1p(torch.abs(w) * u )/torch.log1p(u) ) * torch.sign(w) +torch.tensor(1.))/ torch.tensor(2.) * u +torch.tensor(0.5) #***************************\n",
        "        self.transfer = lambda x: (x - torch.min(x))/(torch.max(x) - torch.min(x)) * u\n",
        "        # self.Embed = FixedEmbedding(c_in, d_model) \n",
        "       \n",
        "        weight = torch.FloatTensor(torch.triu(torch.ones(d_model,d_model),diagonal=0))\n",
        "        weight.require_grad = False\n",
        "        # self.Embed = torch.nn.Embedding.from_pretrained(weight)\n",
        "\n",
        "        self.Embed = nn.Embedding(d_model, d_model)\n",
        "        self.Embed.weight = nn.Parameter(weight, requires_grad=False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = (self.u_law_function(x))\n",
        "        print(x)\n",
        "        print(x.size())\n",
        "        # print(torch.min(x))\n",
        "        x = (self.transfer(x))\n",
        "        x = torch.tensor(x).to(torch.int64)\n",
        "      \n",
        "        x = self.Embed(x)                  #***************************\n",
        "        # x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
        "        print(x.size())\n",
        "        return x\n",
        "\n",
        "\n",
        "class FixedEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model):\n",
        "        super(FixedEmbedding, self).__init__()\n",
        "\n",
        "        w = torch.zeros(c_in, d_model).float()\n",
        "        w.require_grad = False\n",
        "\n",
        "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
        "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
        "\n",
        "        w[:, 0::2] = torch.sin(position * div_term)\n",
        "        w[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.emb = nn.Embedding(c_in, d_model)\n",
        "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x).detach()\n",
        "\n",
        "\n",
        "class TemporalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
        "        super(TemporalEmbedding, self).__init__()\n",
        "\n",
        "        minute_size = 4\n",
        "        hour_size = 24\n",
        "        weekday_size = 7\n",
        "        day_size = 32\n",
        "        month_size = 13\n",
        "\n",
        "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
        "        if freq == 't':\n",
        "            self.minute_embed = Embed(minute_size, d_model)\n",
        "        self.hour_embed = Embed(hour_size, d_model)\n",
        "        self.weekday_embed = Embed(weekday_size, d_model)\n",
        "        self.day_embed = Embed(day_size, d_model)\n",
        "        self.month_embed = Embed(month_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.long()\n",
        "\n",
        "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
        "        hour_x = self.hour_embed(x[:, :, 3])\n",
        "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
        "        day_x = self.day_embed(x[:, :, 1])\n",
        "        month_x = self.month_embed(x[:, :, 0])\n",
        "\n",
        "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
        "\n",
        "\n",
        "class TimeFeatureEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
        "        super(TimeFeatureEmbedding, self).__init__()\n",
        "\n",
        "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
        "        d_inp = freq_map[freq]\n",
        "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "\n",
        "class DataEmbedding(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class DataEmbedding_wo_pos(nn.Module):\n",
        "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
        "        super(DataEmbedding_wo_pos, self).__init__()\n",
        "\n",
        "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
        "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
        "        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type,\n",
        "                                                    freq=freq) if embed_type != 'timeF' else TimeFeatureEmbedding(\n",
        "            d_model=d_model, embed_type=embed_type, freq=freq)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x, x_mark):\n",
        "        x = self.value_embedding(x) + self.temporal_embedding(x_mark)\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMx3dGK_oAJ7"
      },
      "source": [
        "## 1.4SelfAttention_Family"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lIt9j_ZHoVKe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "from math import sqrt\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "from reformer_pytorch import LSHSelfAttention\n",
        "import os\n",
        "\n",
        "\n",
        "class FullAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(FullAttention, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, H, E = queries.shape\n",
        "        _, S, _, D = values.shape\n",
        "        scale = self.scale or 1. / sqrt(E)\n",
        "\n",
        "        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)   #按照爱因斯坦求和约定，当一个单独项目内有标号变量出现两次，一次是上标，一次是下标时，则必须总和所有这单独项目的可能值。\n",
        "\n",
        "        if self.mask_flag:\n",
        "            if attn_mask is None:\n",
        "                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n",
        "\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
        "        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), A)\n",
        "        else:\n",
        "            return (V.contiguous(), None)\n",
        "\n",
        "\n",
        "class ProbAttention(nn.Module):\n",
        "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n",
        "        super(ProbAttention, self).__init__()\n",
        "        self.factor = factor\n",
        "        self.scale = scale\n",
        "        self.mask_flag = mask_flag\n",
        "        self.output_attention = output_attention\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "\n",
        "    def _prob_QK(self, Q, K, sample_k, n_top):  # n_top: c*ln(L_q)\n",
        "        # Q [B, H, L, D]\n",
        "        B, H, L_K, E = K.shape\n",
        "        _, _, L_Q, _ = Q.shape\n",
        "\n",
        "        # calculate the sampled Q_K\n",
        "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
        "        index_sample = torch.randint(L_K, (L_Q, sample_k))  # real U = U_part(factor*ln(L_k))*L_q\n",
        "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
        "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze()\n",
        "\n",
        "        # find the Top_k query with sparisty measurement\n",
        "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
        "        M_top = M.topk(n_top, sorted=False)[1]\n",
        "\n",
        "        # use the reduced Q to calculate Q_K\n",
        "        Q_reduce = Q[torch.arange(B)[:, None, None],\n",
        "                   torch.arange(H)[None, :, None],\n",
        "                   M_top, :]  # factor*ln(L_q)\n",
        "        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1))  # factor*ln(L_q)*L_k\n",
        "\n",
        "        return Q_K, M_top\n",
        "\n",
        "    def _get_initial_context(self, V, L_Q):\n",
        "        B, H, L_V, D = V.shape\n",
        "        if not self.mask_flag:\n",
        "            # V_sum = V.sum(dim=-2)\n",
        "            V_sum = V.mean(dim=-2)\n",
        "            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n",
        "        else:  # use mask\n",
        "            assert (L_Q == L_V)  # requires that L_Q == L_V, i.e. for self-attention only\n",
        "            contex = V.cumsum(dim=-2)\n",
        "        return contex\n",
        "\n",
        "    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n",
        "        B, H, L_V, D = V.shape\n",
        "\n",
        "        if self.mask_flag:\n",
        "            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n",
        "            scores.masked_fill_(attn_mask.mask, -np.inf)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)  # nn.Softmax(dim=-1)(scores)\n",
        "\n",
        "        context_in[torch.arange(B)[:, None, None],\n",
        "        torch.arange(H)[None, :, None],\n",
        "        index, :] = torch.matmul(attn, V).type_as(context_in)\n",
        "        if self.output_attention:\n",
        "            attns = (torch.ones([B, H, L_V, L_V]) / L_V).type_as(attn).to(attn.device)\n",
        "            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n",
        "            return (context_in, attns)\n",
        "        else:\n",
        "            return (context_in, None)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L_Q, H, D = queries.shape\n",
        "        _, L_K, _, _ = keys.shape\n",
        "\n",
        "        queries = queries.transpose(2, 1)\n",
        "        keys = keys.transpose(2, 1)\n",
        "        values = values.transpose(2, 1)\n",
        "\n",
        "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item()  # c*ln(L_k)\n",
        "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item()  # c*ln(L_q)\n",
        "\n",
        "        U_part = U_part if U_part < L_K else L_K\n",
        "        u = u if u < L_Q else L_Q\n",
        "\n",
        "        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
        "\n",
        "        # add scale factor\n",
        "        scale = self.scale or 1. / sqrt(D)\n",
        "        if scale is not None:\n",
        "            scores_top = scores_top * scale\n",
        "        # get the context\n",
        "        context = self._get_initial_context(values, L_Q)\n",
        "        # update the context with selected top_k queries\n",
        "        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n",
        "\n",
        "        return context.contiguous(), attn\n",
        "\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "        d_keys = d_keys or (d_model // n_heads)\n",
        "        d_values = d_values or (d_model // n_heads)\n",
        "\n",
        "        self.inner_attention = attention\n",
        "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
        "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
        "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        B, L, _ = queries.shape\n",
        "        _, S, _ = keys.shape\n",
        "        H = self.n_heads\n",
        "\n",
        "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
        "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
        "        values = self.value_projection(values).view(B, S, H, -1)\n",
        "\n",
        "        out, attn = self.inner_attention(\n",
        "            queries,\n",
        "            keys,\n",
        "            values,\n",
        "            attn_mask\n",
        "        )\n",
        "        out = out.view(B, L, -1)\n",
        "\n",
        "        return self.out_projection(out), attn\n",
        "\n",
        "\n",
        "class ReformerLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, n_heads, d_keys=None,\n",
        "                 d_values=None, causal=False, bucket_size=4, n_hashes=4):\n",
        "        super().__init__()\n",
        "        self.bucket_size = bucket_size\n",
        "        self.attn = LSHSelfAttention(\n",
        "            dim=d_model,\n",
        "            heads=n_heads,\n",
        "            bucket_size=bucket_size,\n",
        "            n_hashes=n_hashes,\n",
        "            causal=causal\n",
        "        )\n",
        "\n",
        "    def fit_length(self, queries):\n",
        "        # inside reformer: assert N % (bucket_size * 2) == 0\n",
        "        B, N, C = queries.shape\n",
        "        if N % (self.bucket_size * 2) == 0:\n",
        "            return queries\n",
        "        else:\n",
        "            # fill the time series\n",
        "            fill_len = (self.bucket_size * 2) - (N % (self.bucket_size * 2))\n",
        "            return torch.cat([queries, torch.zeros([B, fill_len, C]).to(queries.device)], dim=1)\n",
        "\n",
        "    def forward(self, queries, keys, values, attn_mask):\n",
        "        # in Reformer: defalut queries=keys\n",
        "        B, N, C = queries.shape\n",
        "        queries = self.attn(self.fit_length(queries))[:, :N, :]\n",
        "        return queries, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTKTm3kIolKK"
      },
      "source": [
        "## 1.5Transformer_EncDec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qU3EDdg-ongG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, c_in):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        self.downConv = nn.Conv1d(in_channels=c_in,\n",
        "                                  out_channels=c_in,\n",
        "                                  kernel_size=3,\n",
        "                                  padding=2,\n",
        "                                  padding_mode='circular')\n",
        "        self.norm = nn.BatchNorm1d(c_in)\n",
        "        self.activation = nn.ELU()\n",
        "        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downConv(x.permute(0, 2, 1))\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.maxPool(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.attention = attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        new_x, attn = self.attention(\n",
        "            x, x, x,\n",
        "            attn_mask=attn_mask\n",
        "        )\n",
        "        x = x + self.dropout(new_x)\n",
        "\n",
        "        y = x = self.norm1(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm2(x + y), attn\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.attn_layers = nn.ModuleList(attn_layers)\n",
        "        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n",
        "        self.norm = norm_layer\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        # x [B, L, D]\n",
        "        attns = []\n",
        "        if self.conv_layers is not None:\n",
        "            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                x = conv_layer(x)\n",
        "                attns.append(attn)\n",
        "            x, attn = self.attn_layers[-1](x)\n",
        "            attns.append(attn)\n",
        "        else:\n",
        "            for attn_layer in self.attn_layers:\n",
        "                x, attn = attn_layer(x, attn_mask=attn_mask)\n",
        "                attns.append(attn)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        return x, attns\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n",
        "                 dropout=0.1, activation=\"relu\"):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        d_ff = d_ff or 4 * d_model\n",
        "        self.self_attention = self_attention\n",
        "        self.cross_attention = cross_attention\n",
        "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = F.relu if activation == \"relu\" else F.gelu\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        x = x + self.dropout(self.self_attention(\n",
        "            x, x, x,\n",
        "            attn_mask=x_mask\n",
        "        )[0])\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x = x + self.dropout(self.cross_attention(\n",
        "            x, cross, cross,\n",
        "            attn_mask=cross_mask\n",
        "        )[0])\n",
        "\n",
        "        y = x = self.norm2(x)\n",
        "        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n",
        "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
        "\n",
        "        return self.norm3(x + y)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers, norm_layer=None, projection=None):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        self.norm = norm_layer\n",
        "        self.projection = projection\n",
        "\n",
        "    def forward(self, x, cross, x_mask=None, cross_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm0TRcMPSr9a"
      },
      "source": [
        "# 4.data provider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgImJJEOW5fp"
      },
      "source": [
        "## 4.1 data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cdfMzEkNSwzU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from utils.timefeatures import time_features\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Dataset_ETT_hour(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        border1s = [0, 12 * 30 * 24 - self.seq_len, 12 * 30 * 24 + 4 * 30 * 24 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_ETT_minute(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTm1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='t'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        print(df_raw)\n",
        "        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len]\n",
        "        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "\n",
        "\n",
        "class Dataset_Custom(Dataset):\n",
        "    def __init__(self, root_path, flag='train', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, timeenc=0, freq='h'):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['train', 'test', 'val']\n",
        "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.set_type = type_map[flag]\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        cols = list(df_raw.columns)\n",
        "        cols.remove(self.target)\n",
        "        cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        # print(cols)\n",
        "        num_train = int(len(df_raw) * 0.7)\n",
        "        num_test = int(len(df_raw) * 0.2)\n",
        "        num_vali = len(df_raw) - num_train - num_test\n",
        "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
        "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
        "        border1 = border1s[self.set_type]\n",
        "        border2 = border2s[self.set_type]\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            train_data = df_data[border1s[0]:border2s[0]]\n",
        "            self.scaler.fit(train_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        df_stamp = df_raw[['date']][border1:border2]\n",
        "        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        seq_y = self.data_y[r_begin:r_end]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n",
        "    \n",
        "\n",
        "class Dataset_Pred(Dataset):\n",
        "    def __init__(self, root_path, flag='pred', size=None,\n",
        "                 features='S', data_path='ETTh1.csv',\n",
        "                 target='OT', scale=True, inverse=False, timeenc=0, freq='15min', cols=None):\n",
        "        # size [seq_len, label_len, pred_len]\n",
        "        # info\n",
        "        if size == None:\n",
        "            self.seq_len = 24 * 4 * 4\n",
        "            self.label_len = 24 * 4\n",
        "            self.pred_len = 24 * 4\n",
        "        else:\n",
        "            self.seq_len = size[0]\n",
        "            self.label_len = size[1]\n",
        "            self.pred_len = size[2]\n",
        "        # init\n",
        "        assert flag in ['pred']\n",
        "\n",
        "        self.features = features\n",
        "        self.target = target\n",
        "        self.scale = scale\n",
        "        self.inverse = inverse\n",
        "        self.timeenc = timeenc\n",
        "        self.freq = freq\n",
        "        self.cols = cols\n",
        "        self.root_path = root_path\n",
        "        self.data_path = data_path\n",
        "        self.__read_data__()\n",
        "\n",
        "    def __read_data__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
        "                                          self.data_path))\n",
        "        '''\n",
        "        df_raw.columns: ['date', ...(other features), target feature]\n",
        "        '''\n",
        "        if self.cols:\n",
        "            cols = self.cols.copy()\n",
        "            cols.remove(self.target)\n",
        "        else:\n",
        "            cols = list(df_raw.columns)\n",
        "            cols.remove(self.target)\n",
        "            cols.remove('date')\n",
        "        df_raw = df_raw[['date'] + cols + [self.target]]\n",
        "        border1 = len(df_raw) - self.seq_len\n",
        "        border2 = len(df_raw)\n",
        "\n",
        "        if self.features == 'M' or self.features == 'MS':\n",
        "            cols_data = df_raw.columns[1:]\n",
        "            df_data = df_raw[cols_data]\n",
        "        elif self.features == 'S':\n",
        "            df_data = df_raw[[self.target]]\n",
        "\n",
        "        if self.scale:\n",
        "            self.scaler.fit(df_data.values)\n",
        "            data = self.scaler.transform(df_data.values)\n",
        "        else:\n",
        "            data = df_data.values\n",
        "\n",
        "        tmp_stamp = df_raw[['date']][border1:border2]\n",
        "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
        "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len + 1, freq=self.freq)\n",
        "\n",
        "        df_stamp = pd.DataFrame(columns=['date'])\n",
        "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
        "        if self.timeenc == 0:\n",
        "            df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
        "            df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
        "            df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
        "            df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
        "            df_stamp['minute'] = df_stamp.date.apply(lambda row: row.minute, 1)\n",
        "            df_stamp['minute'] = df_stamp.minute.map(lambda x: x // 15)\n",
        "            data_stamp = df_stamp.drop(['date'], 1).values\n",
        "        elif self.timeenc == 1:\n",
        "            data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
        "            data_stamp = data_stamp.transpose(1, 0)\n",
        "\n",
        "        self.data_x = data[border1:border2]\n",
        "        if self.inverse:\n",
        "            self.data_y = df_data.values[border1:border2]\n",
        "        else:\n",
        "            self.data_y = data[border1:border2]\n",
        "        self.data_stamp = data_stamp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        s_begin = index\n",
        "        s_end = s_begin + self.seq_len\n",
        "        r_begin = s_end - self.label_len\n",
        "        r_end = r_begin + self.label_len + self.pred_len\n",
        "\n",
        "        seq_x = self.data_x[s_begin:s_end]\n",
        "        if self.inverse:\n",
        "            seq_y = self.data_x[r_begin:r_begin + self.label_len]\n",
        "        else:\n",
        "            seq_y = self.data_y[r_begin:r_begin + self.label_len]\n",
        "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
        "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
        "\n",
        "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_x) - self.seq_len + 1\n",
        "\n",
        "    def inverse_transform(self, data):\n",
        "        return self.scaler.inverse_transform(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zITfhuNwWve4"
      },
      "source": [
        "## 4.2data_factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "IWZeKnfeUUn7"
      },
      "outputs": [],
      "source": [
        "# from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_dict = {\n",
        "    'ETTh1': Dataset_ETT_hour,\n",
        "    'ETTh2': Dataset_ETT_hour,\n",
        "    'ETTm1': Dataset_ETT_minute,\n",
        "    'ETTm2': Dataset_ETT_minute,\n",
        "    'custom': Dataset_Custom,\n",
        "}\n",
        "\n",
        "\n",
        "def data_provider(args, flag):\n",
        "    Data = data_dict[args.data]\n",
        "    timeenc = 0 if args.embed != 'timeF' else 1\n",
        "    print(Data)\n",
        "    print(timeenc)\n",
        "    if flag == 'test':\n",
        "        shuffle_flag = False\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "    elif flag == 'pred':\n",
        "        shuffle_flag = False\n",
        "        drop_last = False\n",
        "        batch_size = 1\n",
        "        freq = args.freq\n",
        "        Data = Dataset_Pred\n",
        "    else:\n",
        "        shuffle_flag = True\n",
        "        drop_last = True\n",
        "        batch_size = args.batch_size\n",
        "        freq = args.freq\n",
        "\n",
        "    data_set = Data(\n",
        "        root_path=args.root_path,\n",
        "        data_path=args.data_path,\n",
        "        flag=flag,\n",
        "        size=[args.seq_len, args.label_len, args.pred_len],\n",
        "        features=args.features,\n",
        "        target=args.target,\n",
        "        timeenc=timeenc,\n",
        "        freq=freq\n",
        "    )\n",
        "    print(flag, len(data_set))\n",
        "    data_loader = DataLoader(\n",
        "        data_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_flag,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=drop_last)\n",
        "    return data_set, data_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xpHbE97AJFMv"
      },
      "outputs": [],
      "source": [
        "data_set = Dataset_ETT_hour(\n",
        "        root_path='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/',\n",
        "        data_path='REFINED_NBC news G16B3-QP28.csv',\n",
        "        flag='test',\n",
        "        size=[98, 48, 24],\n",
        "        features='M',\n",
        "        target='OT',\n",
        "        timeenc=1,\n",
        "        # freq='d'\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "c5AAmQxXN9JJ"
      },
      "outputs": [],
      "source": [
        "# i = 0\n",
        "# for item in data_set:\n",
        "#   if i < 1:\n",
        "#     i = i + 1\n",
        "#     print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "FhuwQ28lJKTo"
      },
      "outputs": [],
      "source": [
        "# data_provider.timeenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "xN2VPTltANAc"
      },
      "outputs": [],
      "source": [
        "# args.data\n",
        "# args.freq\n",
        "# args.target,\n",
        "# args.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ggqTaWtqBZpE"
      },
      "outputs": [],
      "source": [
        "# args.root_path,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "SMhEdQ1__8a8"
      },
      "outputs": [],
      "source": [
        "# '''data_set'''\n",
        "# i = 0\n",
        "# print(\"data_set:\", data_set)\n",
        "# for item in data_loader:\n",
        "#   i = i+1\n",
        "#   if i < 5:\n",
        "#     print(\"item:\", item)\n",
        "#     print(\"item size:\", len(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn4mhqeGWGbT"
      },
      "source": [
        "# 6.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEQKNrGVV1nC"
      },
      "source": [
        "## 6.0.transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "3aIRCR44bstE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Embed import DataEmbedding, DataEmbedding_wo_pos\n",
        "# from layers.AutoCorrelation import AutoCorrelation, AutoCorrelationLayer\n",
        "# from layers.Autoformer_EncDec import Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoformer is the first method to achieve the series-wise connection,\n",
        "    with inherent O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_transformer, self).__init__()\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.label_len = configs.label_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Decomp\n",
        "        kernel_size = configs.moving_avg\n",
        "        self.decomp = series_decomp(kernel_size)\n",
        "\n",
        "        # Embedding\n",
        "        # The series-wise connection inherently contains the sequential information.\n",
        "        # Thus, we can discard the position embedding of transformers.\n",
        "        self.enc_embedding = DataEmbedding_wo_pos(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding_wo_pos(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                                  configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(True, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AutoCorrelationLayer(\n",
        "                        AutoCorrelation(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                        output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.c_out,\n",
        "                    configs.d_ff,\n",
        "                    moving_avg=configs.moving_avg,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=my_Layernorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # decomp init\n",
        "        mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, self.pred_len, 1)\n",
        "        zeros = torch.zeros([x_dec.shape[0], self.pred_len, x_dec.shape[2]], device=x_enc.device)\n",
        "        seasonal_init, trend_init = self.decomp(x_enc)\n",
        "        # decoder input\n",
        "        trend_init = torch.cat([trend_init[:, -self.label_len:, :], mean], dim=1)\n",
        "        seasonal_init = torch.cat([seasonal_init[:, -self.label_len:, :], zeros], dim=1)\n",
        "        # enc\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        # dec\n",
        "        dec_out = self.dec_embedding(seasonal_init, x_mark_dec)\n",
        "        seasonal_part, trend_part = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask,\n",
        "                                                 trend=trend_init)\n",
        "        # final\n",
        "        dec_out = trend_part + seasonal_part\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh-wb_oDcZq1"
      },
      "source": [
        "## 6.1.autoformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "UzH_MdaLV6fo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_autoformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Vanilla Transformer with O(L^2) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_autoformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO1t1HZNfST2"
      },
      "source": [
        "## 6.2 informer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "d8hMhyLGfUJO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from utils.masking import TriangularCausalMask, ProbMask\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import FullAttention, ProbAttention, AttentionLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_informer(nn.Module):\n",
        "    \"\"\"\n",
        "    Informer with Propspare attention in O(LlogL) complexity\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(Model_informer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        self.dec_embedding = DataEmbedding(configs.dec_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout,\n",
        "                                      output_attention=configs.output_attention),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            [\n",
        "                ConvLayer(\n",
        "                    configs.d_model\n",
        "                ) for l in range(configs.e_layers - 1)\n",
        "            ] if configs.distil else None,\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(\n",
        "            [\n",
        "                DecoderLayer(\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(True, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    AttentionLayer(\n",
        "                        ProbAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=False),\n",
        "                        configs.d_model, configs.n_heads),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation,\n",
        "                )\n",
        "                for l in range(configs.d_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model),\n",
        "            projection=nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "\n",
        "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
        "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return dec_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phxv-52XfZxY"
      },
      "source": [
        "## 6.3 reformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OWuGfTFWfhMQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from layers.Transformer_EncDec import Decoder, DecoderLayer, Encoder, EncoderLayer, ConvLayer\n",
        "# from layers.SelfAttention_Family import ReformerLayer\n",
        "# from layers.Embed import DataEmbedding\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Model_reformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Reformer with O(LlogL) complexity\n",
        "    - It is notable that Reformer is not proposed for time series forecasting, in that it cannot accomplish the cross attention.\n",
        "    - Here is only one adaption in BERT-style, other possible implementations can also be acceptable.\n",
        "    - The hyper-parameters, such as bucket_size and n_hashes, need to be further tuned.\n",
        "    The official repo of Reformer (https://github.com/lucidrains/reformer-pytorch) can be very helpful, if you have any questiones.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super(Model_reformer, self).__init__()\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.pred_len = configs.pred_len\n",
        "        self.output_attention = configs.output_attention\n",
        "\n",
        "        # Embedding\n",
        "        self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n",
        "                                           configs.dropout)\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(\n",
        "            [\n",
        "                EncoderLayer(\n",
        "                    ReformerLayer(None, configs.d_model, configs.n_heads, bucket_size=configs.bucket_size,\n",
        "                                  n_hashes=configs.n_hashes),\n",
        "                    configs.d_model,\n",
        "                    configs.d_ff,\n",
        "                    dropout=configs.dropout,\n",
        "                    activation=configs.activation\n",
        "                ) for l in range(configs.e_layers)\n",
        "            ],\n",
        "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
        "        )\n",
        "        self.projection = nn.Linear(configs.d_model, configs.c_out, bias=True)\n",
        "\n",
        "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec,\n",
        "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
        "        # add placeholder\n",
        "        x_enc = torch.cat([x_enc, x_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        x_mark_enc = torch.cat([x_mark_enc, x_mark_dec[:, -self.pred_len:, :]], dim=1)\n",
        "        # Reformer: encoder only\n",
        "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
        "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
        "        enc_out = self.projection(enc_out)\n",
        "\n",
        "        if self.output_attention:\n",
        "            return enc_out[:, -self.pred_len:, :], attns\n",
        "        else:\n",
        "            return enc_out[:, -self.pred_len:, :]  # [B, L, D]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyAd4Xzgdn7b"
      },
      "source": [
        "# 2.exp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZnDaWqEd1cD"
      },
      "source": [
        "## 2.1 exp_basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "_kDMmjLddsCC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Exp_Basic(object):\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.device = self._acquire_device()\n",
        "        self.model = self._build_model().to(self.device)\n",
        "\n",
        "    def _build_model(self):\n",
        "        raise NotImplementedError\n",
        "        return None\n",
        "\n",
        "    def _acquire_device(self):\n",
        "        if self.args.use_gpu:\n",
        "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
        "                self.args.gpu) if not self.args.use_multi_gpu else self.args.devices\n",
        "            device = torch.device('cuda:{}'.format(self.args.gpu))\n",
        "            print('Use GPU: cuda:{}'.format(self.args.gpu))\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "            print('Use CPU')\n",
        "        return device\n",
        "\n",
        "    def _get_data(self):\n",
        "        pass\n",
        "\n",
        "    def vali(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def test(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaqW13S4fAXG"
      },
      "source": [
        "## 2.2 exp_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "hoDRz8yifA2I"
      },
      "outputs": [],
      "source": [
        "# from data_provider.data_factory import data_provider\n",
        "# from exp.exp_basic import Exp_Basic\n",
        "# from models import Informer, Autoformer, Transformer, Reformer\n",
        "# from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
        "# from utils.metrics import metric\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Exp_Main(Exp_Basic):\n",
        "    def __init__(self, args):\n",
        "        super(Exp_Main, self).__init__(args)\n",
        "\n",
        "    def _build_model(self):\n",
        "        model_dict = {\n",
        "            'Autoformer': Model_autoformer,\n",
        "            'Transformer': Model_transformer,\n",
        "            'Informer': Model_informer,\n",
        "            'Reformer': Model_reformer,\n",
        "        }\n",
        "        # model_dict = {\n",
        "        #     'Autoformer': Autoformer,\n",
        "        #     'Transformer': Transformer,\n",
        "        #     'Informer': Informer,\n",
        "        #     'Reformer': Reformer,\n",
        "        # }\n",
        "        # model = model_dict[self.args.model].Model(self.args).float()\n",
        "        model = model_dict[self.args.model](self.args).float()\n",
        "\n",
        "\n",
        "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
        "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
        "        return model\n",
        "\n",
        "    def _get_data(self, flag):\n",
        "        data_set, data_loader = data_provider(self.args, flag)\n",
        "        return data_set, data_loader\n",
        "\n",
        "    def _select_optimizer(self):\n",
        "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
        "        return model_optim\n",
        "\n",
        "    def _select_criterion(self):\n",
        "        criterion = nn.MSELoss()\n",
        "        return criterion\n",
        "\n",
        "    def vali(self, vali_data, vali_loader, criterion):\n",
        "        total_loss = []\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "\n",
        "                pred = outputs.detach().cpu()\n",
        "                true = batch_y.detach().cpu()\n",
        "\n",
        "                loss = criterion(pred, true)\n",
        "\n",
        "                total_loss.append(loss)\n",
        "        total_loss = np.average(total_loss)\n",
        "        self.model.train()\n",
        "        return total_loss\n",
        "\n",
        "    def train(self, setting):\n",
        "        train_data, train_loader = self._get_data(flag='train')\n",
        "        vali_data, vali_loader = self._get_data(flag='val')\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "\n",
        "        path = os.path.join(self.args.checkpoints, setting)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        time_now = time.time()\n",
        "\n",
        "        train_steps = len(train_loader)\n",
        "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
        "\n",
        "        model_optim = self._select_optimizer()\n",
        "        criterion = self._select_criterion()\n",
        "\n",
        "        if self.args.use_amp:\n",
        "            scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "        for epoch in range(self.args.train_epochs):\n",
        "            iter_count = 0\n",
        "            train_loss = []\n",
        "\n",
        "            self.model.train()\n",
        "            epoch_time = time.time()\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n",
        "                iter_count += 1\n",
        "                model_optim.zero_grad()\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                        f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                        loss = criterion(outputs, batch_y)\n",
        "                        train_loss.append(loss.item())\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark, batch_y)\n",
        "\n",
        "                    f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "                    train_loss.append(loss.item())\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
        "                    speed = (time.time() - time_now) / iter_count\n",
        "                    left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
        "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
        "                    iter_count = 0\n",
        "                    time_now = time.time()\n",
        "\n",
        "                if self.args.use_amp:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(model_optim)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    loss.backward()\n",
        "                    model_optim.step()\n",
        "\n",
        "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
        "            train_loss = np.average(train_loss)\n",
        "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
        "            test_loss = self.vali(test_data, test_loader, criterion)\n",
        "\n",
        "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
        "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
        "            early_stopping(vali_loss, self.model, path)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "            adjust_learning_rate(model_optim, epoch + 1, self.args)\n",
        "\n",
        "        best_model_path = path + '/' + 'checkpoint.pth'\n",
        "        self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def test(self, setting, test=0):\n",
        "        test_data, test_loader = self._get_data(flag='test')\n",
        "        if test:\n",
        "            print('loading model')\n",
        "            self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
        "\n",
        "        preds = []\n",
        "        trues = []\n",
        "        folder_path = './test_results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float().to(self.device)\n",
        "\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "\n",
        "                f_dim = -1 if self.args.features == 'MS' else 0\n",
        "                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
        "                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
        "                outputs = outputs.detach().cpu().numpy()\n",
        "                batch_y = batch_y.detach().cpu().numpy()\n",
        "\n",
        "                pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n",
        "\n",
        "                preds.append(pred)\n",
        "                trues.append(true)\n",
        "                if i % 20 == 0:\n",
        "                    input = batch_x.detach().cpu().numpy()\n",
        "                    gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
        "                    pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
        "                    visual(gt, pd, os.path.join(folder_path, str(i) + '.pdf'))\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        trues = np.array(trues)\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
        "        print('test shape:', preds.shape, trues.shape)\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
        "        print('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f = open(\"result.txt\", 'a')\n",
        "        f.write(setting + \"  \\n\")\n",
        "        f.write('mse:{}, mae:{}'.format(mse, mae))\n",
        "        f.write('\\n')\n",
        "        f.write('\\n')\n",
        "        f.close()\n",
        "\n",
        "        np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
        "        np.save(folder_path + 'pred.npy', preds)\n",
        "        np.save(folder_path + 'true.npy', trues)\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, setting, load=False):\n",
        "        pred_data, pred_loader = self._get_data(flag='pred')\n",
        "\n",
        "        if load:\n",
        "            path = os.path.join(self.args.checkpoints, setting)\n",
        "            best_model_path = path + '/' + 'checkpoint.pth'\n",
        "            self.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "        preds = []\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(pred_loader):\n",
        "                batch_x = batch_x.float().to(self.device)\n",
        "                batch_y = batch_y.float()\n",
        "                batch_x_mark = batch_x_mark.float().to(self.device)\n",
        "                batch_y_mark = batch_y_mark.float().to(self.device)\n",
        "\n",
        "                # decoder input\n",
        "                dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[2]]).float()\n",
        "                dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
        "                # encoder - decoder\n",
        "                if self.args.use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        if self.args.output_attention:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                        else:\n",
        "                            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                else:\n",
        "                    if self.args.output_attention:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                    else:\n",
        "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "                pred = outputs.detach().cpu().numpy()  # .squeeze()\n",
        "                preds.append(pred)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "\n",
        "        # result save\n",
        "        folder_path = './results/' + setting + '/'\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "        np.save(folder_path + 'real_prediction.npy', preds)\n",
        "\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUdH5LufYdg4"
      },
      "source": [
        "# predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb1pRBEDYiqM",
        "outputId": "0b0f069d-40e3-46a1-c147-df305331198b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\t\t # 查看GPu设备是否可用\n",
        "print(torch.cuda.device_count()) \t\t# 查看GPu设备数量\n",
        "print(torch.cuda.get_device_name())   \t# 查看当前GPu设备名称，默认设备id从0开始\n",
        "print(torch.cuda.current_device())\t\t# 查看当前GPu设备id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yYISGR-rbc2_"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available() \n",
        "import torch\n",
        "torch.cuda.set_device(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3PkcjfqbkHP",
        "outputId": "a5f60d57-f4aa-4876-d855-4290569e8b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Args in experiment:\n",
            "{'target': 'OT', 'des': 'Exp', 'dropout': 0.05, 'num_workers': 10, 'lradj': 'type1', 'devices': '0', 'use_gpu': False, 'use_multi_gpu': False, 'freq': 'h', 'checkpoints': '/content/drive/MyDrive/DATA_reformer/checkpoints/', 'bucket_size': 4, 'n_hashes': 4, 'is_trainging': True, 'root_path': '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', 'data_path': 'REFINED_NBC news G16B3-QP28.csv', 'model_id': 'ETTh1_96_24', 'model': 'Autoformer', 'data': 'ETTh1', 'features': 'M', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'e_layers': 2, 'd_layers': 1, 'n_heads': 8, 'factor': 1, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'itr': 1, 'd_ff': 2048, 'moving_avg': 25, 'distil': True, 'output_attention': False, 'patience': 3, 'learning_rate': 0.0001, 'batch_size': 32, 'embed': 'timeF', 'activation': 'gelu', 'use_amp': False, 'loss': 'mse', 'train_epochs': 10}\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "# from exp.exp_main import Exp_Main#exp stands for experiments\n",
        "import random\n",
        "import numpy as np\n",
        "# from utils.tools import dotdict\n",
        "\n",
        "fix_seed = 2021 \n",
        "random.seed(fix_seed)\n",
        "# torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Autoformer & Transformer family for Time Series Forecasting')\n",
        "\n",
        "# basic config\n",
        "parser.add_argument('--is_training', type=int, required=True, default=1, help='status')\n",
        "parser.add_argument('--model_id', type=str, required=True, default='test', help='model id')#模型id\n",
        "parser.add_argument('--model', type=str, required=True, default='Autoformer',#选择模型\n",
        "                    help='model name, options: [Autoformer, Informer, Transformer]')\n",
        "\n",
        "# data loader\n",
        "parser.add_argument('--data', type=str, required=True, default='ETTm1', help='dataset type')#数据类型\n",
        "parser.add_argument('--root_path', type=str, default='/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/', help='root path of the data file')#数据文件夹路径\n",
        "parser.add_argument('--data_path', type=str, default='REFINED_NBC news G16B3-QP28.csv', help='data file')#具体文件\n",
        "parser.add_argument('--features', type=str, default='M',\n",
        "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')#预测类别\n",
        "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')#不太懂 OT好像代表Output Target,要预测的单变量\n",
        "parser.add_argument('--freq', type=str, default='h',\n",
        "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
        "parser.add_argument('--checkpoints', type=str, default='/content/drive/MyDrive/DATA_reformer/checkpoints/', help='location of model checkpoints')#保存模型\n",
        "\n",
        "# forecasting task\n",
        "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')#输入序列长度\n",
        "parser.add_argument('--label_len', type=int, default=48, help='start token length')#这个label_len未完全搞懂\n",
        "parser.add_argument('--pred_len', type=int, default=24, help='prediction sequence length')#输出序列长度\n",
        "\n",
        "# model define\n",
        "parser.add_argument('--bucket_size', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--n_hashes', type=int, default=4, help='for Reformer')#Reformer专用属性\n",
        "parser.add_argument('--enc_in', type=int, default=7, help='encoder input size')#encoder input size\n",
        "parser.add_argument('--dec_in', type=int, default=7, help='decoder input size')#decoder input size\n",
        "parser.add_argument('--c_out', type=int, default=7, help='output size')#输出长度\n",
        "parser.add_argument('--d_model', type=int, default=512, help='dimension of model')#dimension of model\n",
        "parser.add_argument('--n_heads', type=int, default=8, help='num of heads')#num of heads \n",
        "parser.add_argument('--e_layers', type=int, default=2, help='num of encoder layers')#num of encoder layers\n",
        "parser.add_argument('--d_layers', type=int, default=1, help='num of decoder layers')#num of decoder layers\n",
        "parser.add_argument('--d_ff', type=int, default=2048, help='dimension of fcn')#dimension of fcn\n",
        "parser.add_argument('--moving_avg', type=int, default=25, help='window size of moving average')#窗口滑动平均数\n",
        "parser.add_argument('--factor', type=int, default=1, help='attn factor')#attn factor不太理解\n",
        "parser.add_argument('--distil', action='store_false',\n",
        "                    help='whether to use distilling in encoder, using this argument means not using distilling',\n",
        "                    default=True)#是否在encoder里面使用知识蒸馏\n",
        "parser.add_argument('--dropout', type=float, default=0.05, help='dropout')#dropout\n",
        "parser.add_argument('--embed', type=str, default='timeF',\n",
        "                    help='time features encoding, options:[timeF, fixed, learned]')#time features encoding不太能get到\n",
        "parser.add_argument('--activation', type=str, default='gelu', help='activation')#激活函数default=gelu\n",
        "parser.add_argument('--output_attention', action='store_true', help='whether to output attention in encoder')#encoder的output_attention是否输出\n",
        "parser.add_argument('--do_predict', action='store_true', help='whether to predict unseen future data')#是否预测未见的未来数据,也就是是否进行推理的意思\n",
        "\n",
        "# optimization\n",
        "parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')# num_workers是加载数据(batch)的线程数目\n",
        "parser.add_argument('--itr', type=int, default=2, help='experiments times')#实验次数\n",
        "parser.add_argument('--train_epochs', type=int, default=10, help='train epochs')#就是epoch\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')#bathsize\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')#patience: 当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
        "parser.add_argument('--learning_rate', type=float, default=0.0001, help='optimizer learning rate')#lr\n",
        "parser.add_argument('--des', type=str, default='test', help='exp description')#test\n",
        "parser.add_argument('--loss', type=str, default='mse', help='loss function')#loss is mse\n",
        "parser.add_argument('--lradj', type=str, default='type1', help='adjust learning rate')#adjust learning-rate\n",
        "parser.add_argument('--use_amp', action='store_true', help='use automatic mixed precision training', default=False)#使用自动混合精度训练\n",
        "\n",
        "# GPU\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "args = dotdict()\n",
        "args.target = 'OT'\n",
        "args.des = 'test'\n",
        "args.dropout = 0.05\n",
        "args.num_workers = 10\n",
        "# args.gpu = 0\n",
        "args.lradj = 'type1'\n",
        "args.devices = '0'\n",
        "args.use_gpu = False\n",
        "args.use_multi_gpu = False\n",
        "# if args.use_gpu and args.use_multi_gpu: #是否使用多卡的判断\n",
        "#     args.dvices = args.devices.replace(' ', '')\n",
        "#     device_ids = args.devices.split(',')\n",
        "#     args.device_ids = [int(id_) for id_ in device_ids]\n",
        "#     args.gpu = args.device_ids[0]\n",
        "args.freq = 'h'\n",
        "args.checkpoints = '/content/drive/MyDrive/DATA_reformer/checkpoints/'\n",
        "args.bucket_size = 4\n",
        "args.n_hashes = 4\n",
        "args.is_trainging = True\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path ='REFINED_NBC news G16B3-QP28.csv' \n",
        "args.model_id='ETTh1_96_24'\n",
        "args.model = 'Autoformer'\n",
        "args.data = 'ETTh1'\n",
        "args.features = 'M'\n",
        "args.seq_len = 96\n",
        "args.label_len = 48\n",
        "args.pred_len = 24\n",
        "args.e_layers = 2\n",
        "args.d_layers = 1\n",
        "args.n_heads = 8\n",
        "args.factor = 1\n",
        "args.enc_in = 7\n",
        "args.dec_in =7\n",
        "args.c_out = 7\n",
        "args.d_model = 512\n",
        "\n",
        "args.des = 'Exp'\n",
        "args.itr = 1      #1\n",
        "args.d_ff = 2048\n",
        "args.moving_avg = 25\n",
        "args.factor = 1\n",
        "args.distil = True\n",
        "args.output_attention = False\n",
        "args.patience= 3\n",
        "args.learning_rate = 0.0001\n",
        "args.batch_size = 32 \n",
        "args.embed = 'timeF'\n",
        "args.activation = 'gelu'\n",
        "args.use_amp = False\n",
        "args.loss = 'mse'\n",
        "args.train_epochs = 10    #10\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "# Exp = Exp_Main\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "gkA3f_QHeIlG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7476a7e-d812-4228-89ce-f518a2f88a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use CPU\n",
            "1\n",
            ">>>>>>>start training : ETTh1_96_24_Autoformer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "train 8521\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "val 2857\n",
            "<class '__main__.Dataset_ETT_hour'>\n",
            "1\n",
            "test 2857\n",
            "tensor([[[-1.1969e+01,  5.5727e+01,  2.4075e+01,  ...,  5.2274e+02,\n",
            "           4.8019e+02,  2.4075e+01],\n",
            "         [-1.1957e+01,  5.5727e+01,  3.6863e+01,  ...,  5.2506e+02,\n",
            "           4.9168e+02,  3.6863e+01],\n",
            "         [-1.1945e+01,  5.5727e+01,  2.9536e+01,  ...,  5.2781e+02,\n",
            "           4.9053e+02,  2.9536e+01],\n",
            "         ...,\n",
            "         [-1.0829e+01,  5.5727e+01,  2.4188e+01,  ...,  5.3630e+02,\n",
            "           5.2888e+02,  2.4188e+01],\n",
            "         [-1.0817e+01,  5.5727e+01,  2.2235e+01,  ...,  5.3181e+02,\n",
            "           5.3094e+02,  2.2235e+01],\n",
            "         [-1.0804e+01,  5.3571e+02,  7.7150e+01,  ...,  5.3850e+02,\n",
            "           5.3070e+02,  7.7150e+01]],\n",
            "\n",
            "        [[ 3.4169e+01,  5.5727e+01,  3.2188e+01,  ...,  7.5359e+01,\n",
            "           4.5439e+02,  3.2188e+01],\n",
            "         [ 3.4206e+01,  5.3571e+02,  4.4087e+02,  ...,  4.7965e+01,\n",
            "           3.9754e+02,  4.4087e+02],\n",
            "         [ 3.4244e+01,  5.5727e+01,  2.5359e+01,  ...,  3.8095e+02,\n",
            "           4.6078e+02,  2.5359e+01],\n",
            "         ...,\n",
            "         [ 3.7792e+01,  5.3571e+02,  5.4516e+02,  ...,  6.5586e+01,\n",
            "           2.2869e+02,  5.4516e+02],\n",
            "         [ 3.7833e+01,  5.5727e+01,  2.2912e+01,  ...,  2.4799e+01,\n",
            "           5.1044e+01,  2.2912e+01],\n",
            "         [ 3.7874e+01,  5.5727e+01,  2.3296e+01,  ...,  3.9845e+01,\n",
            "           7.2442e+01,  2.3296e+01]],\n",
            "\n",
            "        [[-5.0926e-01,  5.3571e+02,  4.6242e+02,  ..., -2.0799e+01,\n",
            "          -1.0178e+01,  4.6242e+02],\n",
            "         [-4.9326e-01,  5.5727e+01,  3.6140e+01,  ..., -1.7688e+01,\n",
            "          -1.1273e+01,  3.6140e+01],\n",
            "         [-4.7727e-01,  5.5727e+01,  2.8179e+01,  ..., -1.7927e+01,\n",
            "          -1.2682e+01,  2.8179e+01],\n",
            "         ...,\n",
            "         [ 1.0055e+00,  5.5727e+01,  2.7746e+01,  ...,  3.6911e+02,\n",
            "           4.9798e+02,  2.7746e+01],\n",
            "         [ 1.0221e+00,  5.5727e+01,  3.3652e+01,  ...,  4.7093e+02,\n",
            "           5.0241e+02,  3.3652e+01],\n",
            "         [ 1.0387e+00,  5.5727e+01,  3.4841e+01,  ...,  4.8636e+02,\n",
            "           5.0789e+02,  3.4841e+01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.1200e+01,  5.3571e+02,  1.1282e+02,  ...,  5.3869e+02,\n",
            "           5.1803e+02,  1.1282e+02],\n",
            "         [-1.1188e+01,  5.5727e+01,  2.4188e+01,  ...,  5.3823e+02,\n",
            "           5.1889e+02,  2.4188e+01],\n",
            "         [-1.1176e+01,  5.5727e+01,  3.0610e+01,  ...,  5.4108e+02,\n",
            "           5.2122e+02,  3.0610e+01],\n",
            "         ...,\n",
            "         [-1.0039e+01,  5.5727e+01,  2.1437e+01,  ...,  5.3513e+02,\n",
            "           5.2122e+02,  2.1437e+01],\n",
            "         [-1.0026e+01,  5.5727e+01,  2.1861e+01,  ...,  5.3248e+02,\n",
            "           5.1952e+02,  2.1861e+01],\n",
            "         [-1.0013e+01,  5.5727e+01,  2.1411e+01,  ...,  5.2998e+02,\n",
            "           5.1826e+02,  2.1411e+01]],\n",
            "\n",
            "        [[ 5.2375e+02,  5.5727e+01,  6.7339e+01,  ...,  4.0173e+02,\n",
            "           2.7584e+01,  6.7339e+01],\n",
            "         [ 5.2376e+02,  5.5727e+01,  3.7677e+01,  ...,  4.2304e+02,\n",
            "           3.8188e+01,  3.7677e+01],\n",
            "         [ 5.2378e+02,  5.3571e+02,  5.2592e+02,  ...,  4.4657e+02,\n",
            "           3.0838e+01,  5.2592e+02],\n",
            "         ...,\n",
            "         [ 5.2487e+02,  5.5727e+01,  3.8603e+02,  ...,  5.1964e+02,\n",
            "           5.0681e+02,  3.8603e+02],\n",
            "         [ 5.2488e+02,  5.3571e+02,  5.3044e+02,  ...,  5.1967e+02,\n",
            "           5.0126e+02,  5.3044e+02],\n",
            "         [ 5.2489e+02,  5.5727e+01,  9.4378e+01,  ...,  5.1533e+02,\n",
            "           4.9888e+02,  9.4378e+01]],\n",
            "\n",
            "        [[ 5.1650e+02,  5.5727e+01,  3.1949e+01,  ...,  5.2173e+02,\n",
            "           5.3206e+02,  3.1949e+01],\n",
            "         [ 5.1651e+02,  5.3571e+02,  4.8559e+02,  ...,  5.2729e+02,\n",
            "           5.2718e+02,  4.8559e+02],\n",
            "         [ 5.1653e+02,  5.5727e+01,  3.4116e+01,  ...,  5.2509e+02,\n",
            "           5.3327e+02,  3.4116e+01],\n",
            "         ...,\n",
            "         [ 5.1783e+02, -3.3989e+01,  5.6767e+02,  ...,  5.0993e+02,\n",
            "           4.9538e+02,  5.6767e+02],\n",
            "         [ 5.1784e+02,  5.5727e+01,  3.8388e+01,  ...,  4.9374e+02,\n",
            "           4.8576e+02,  3.8388e+01],\n",
            "         [ 5.1785e+02,  5.5727e+01,  7.8401e+01,  ...,  5.0080e+02,\n",
            "           4.9217e+02,  7.8401e+01]]])\n",
            "torch.Size([32, 96, 7])\n",
            "torch.Size([32, 96, 7, 512])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-c85662ee7b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#setting是用来保存模型的名字用的，很细节\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-f819c66e2a9e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, setting)\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0mf_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MS'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-0155571b5337>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_enc, x_mark_enc, x_dec, x_mark_dec, enc_self_mask, dec_self_mask, dec_enc_mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0menc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mark_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_self_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-af7ad0911907>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_mark)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mark\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (96) at non-singleton dimension 2"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "\n",
        "for ii in range(args.itr):#itr就是实验次数可不是epoch，parser.add_argument('--itr', type=int, default=2, help='experiments times')\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
        "        args.model_id,\n",
        "        args.model,\n",
        "        args.data,\n",
        "        args.features,\n",
        "        args.seq_len,\n",
        "        args.label_len,\n",
        "        args.pred_len,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        args.d_layers,\n",
        "        args.d_ff,\n",
        "        args.factor,\n",
        "        args.embed,\n",
        "        args.distil,\n",
        "        args.des, ii)\n",
        "\n",
        "    exp = Exp_Main(args)  # set experiments\n",
        "    print(1)\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)#setting是用来保存模型的名字用的，很细节\n",
        "    print(2)\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "    torch.cuda.empty_cache()\n",
        "    print(3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzsdzOBEZmhx"
      },
      "source": [
        "# plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITsBvf3CZrKy"
      },
      "outputs": [],
      "source": [
        "# custom data: xxx.csv\n",
        "# data features: ['date', ...(other features), target feature]\n",
        "\n",
        "# we take ETTh2 as an example #模仿informer 的 colab example的custom_dataset与predict部分\n",
        "import pandas as pd\n",
        "args.root_path = '/content/drive/MyDrive/DATA_reformer/datasets/all_six_datasets/ETT-small/'\n",
        "args.data_path = 'ETTh2.csv'\n",
        "\n",
        "df = pd.read_csv(os.path.join(args.root_path, args.data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0NgpX76cK2S"
      },
      "outputs": [],
      "source": [
        "args.do_predict = True\n",
        "if args.do_predict:\n",
        "    print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    prediction=exp.predict(setting, True)#data_factory做好了pred里面的batch_size=1的情况，是autoformer在informer基础之上做的\n",
        "    torch.cuda.empty_cache()\n",
        "    print('>>>end>>>>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Kr9FozffdW"
      },
      "outputs": [],
      "source": [
        "setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_jTxIgOclvQ"
      },
      "outputs": [],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyQ5MQyGcYWb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "#预测OT\n",
        "plt.plot(prediction[-1,:,-1])#由于prediction.shape是[1,24,7]那么batch只有1 索引只能是0或-1 都是代表batch这一维本身\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "plt.plot(prediction[0,:,-1])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "# draw HUFL prediction\n",
        "plt.plot(prediction[0,:,0])#没问题\n",
        "print(prediction.shape)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veiY5xDj5nYU"
      },
      "source": [
        "# try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6YDJ0TC4nyx"
      },
      "outputs": [],
      "source": [
        "exp.train(setting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snWDvZfm5gaa"
      },
      "outputs": [],
      "source": [
        "root_path=args.root_path\n",
        "data_path=args.data_path\n",
        "print(\"root_path:\", root_path)\n",
        "print(\"data_path:\", data_path)\n",
        "print(\"[args.seq_len, args.label_len, args.pred_len]:\", [args.seq_len, args.label_len, args.pred_len])\n",
        "print(\"args.features:\", args.features)\n",
        "print(\"args.target:\", args.target)\n",
        "print(\"args.freq:\", args.freq)\n",
        "\n",
        "data_set, data_loader = data_provider(args, flag='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmJCZCAI64eS"
      },
      "outputs": [],
      "source": [
        "data_set\n",
        "i = 0\n",
        "print(\"data_set:\", data_set)\n",
        "for item in data_loader:\n",
        "  i = i+1\n",
        "  if i < 5:\n",
        "    print(\"item:\", item)\n",
        "    print(\"item size:\", len(item))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "XJjvS08Eltub"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PQ9i2_q8TI9b",
        "fXWOL3TaKzz2",
        "Lm0TRcMPSr9a",
        "JzsdzOBEZmhx"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}